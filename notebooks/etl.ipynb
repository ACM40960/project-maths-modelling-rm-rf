{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15060132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import ast\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import sys\n",
    "import nbformat\n",
    "from git import Repo, GitCommandError\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from docx import Document as DocxDocument\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eee836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_low_value_file(filepath):\n",
    "    low_value_exts = [\n",
    "        '.css', '.min.js', '.json', '.svg', '.csv', '.xlsx', '.xls',\n",
    "        '.log', '.lock', '.pyc', '.pyo', '.pyd', '.class', '.jar', '.war',\n",
    "        '.o', '.obj', '.dll', '.exe', '.so', '.a', '.db', '.sqlite', '.sqlite3',\n",
    "        '.bak', '.tmp', '.ico', '.icns', '.pdf', '.docx', '.pptx',\n",
    "        '.7z', '.zip', '.tar', '.gz', '.rar', '.iml'\n",
    "    ]\n",
    "\n",
    "    low_value_files = [\n",
    "        'readme.md', 'license', '.gitignore', '.gitattributes', 'post-update.sample',\n",
    "        'fsmonitor-watchman.sample', 'pre-commit', 'pre-push', 'commit-msg',\n",
    "        'tags', 'head', 'config', 'description', 'index', '.editorconfig',\n",
    "        '.prettierrc', '.eslintrc', '.gitmodules', '.mailmap', '.clang-format',\n",
    "        'pipfile.lock', 'yarn.lock', 'package-lock.json', '.env', '.env.example', '.npmrc',\n",
    "        'update.sample'\n",
    "    ]\n",
    "\n",
    "    low_value_dirs = {\n",
    "        '.git', '.vscode', '.idea', '__pycache__',\n",
    "        'node_modules', 'dist', 'build', '.pytest_cache'\n",
    "    }\n",
    "\n",
    "    filepath_str = str(filepath).lower()\n",
    "    parts = set(Path(filepath).parts)\n",
    "\n",
    "    return (\n",
    "        Path(filepath).suffix.lower() in low_value_exts or\n",
    "        os.path.basename(filepath).lower() in low_value_files or\n",
    "        any(d in parts for d in low_value_dirs) or\n",
    "        'mock' in filepath_str\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a2ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_repo(repo_url, clone_path=\"tmp_repo\") -> str:\n",
    "    \"\"\"\n",
    "    Shallow-clone the repo at the latest commit only and return the clone path.\n",
    "    \"\"\"\n",
    "    if os.path.exists(clone_path):\n",
    "        shutil.rmtree(clone_path, ignore_errors=True)\n",
    "    Repo.clone_from(repo_url, clone_path, depth=1)\n",
    "    return clone_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chunks_to_faiss(repo_path: str, index_dir: str = \"docs_index\") -> list[Document]:\n",
    "    chunks = []\n",
    "    repo_path = Path(repo_path)\n",
    "\n",
    "    # 1. README files\n",
    "    for readme_name in (\"README.md\", \"README.rst\", \"README.txt\"):\n",
    "        readme_path = repo_path / readme_name\n",
    "        if readme_path.exists():\n",
    "            content = readme_path.read_text(encoding=\"utf-8\").strip()\n",
    "            if 50 < len(content) < 5000:\n",
    "                chunks.append(Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\n",
    "                        \"source\": str(readme_path),\n",
    "                        \"file_ext\": \"text\",\n",
    "                        \"type\": \"readme\",\n",
    "                        \"name\": readme_name,\n",
    "                        \"lines\": f\"1-{content.count(chr(10)) + 1}\"\n",
    "                    }\n",
    "                ))\n",
    "            break\n",
    "\n",
    "    # 2. Other Markdown files\n",
    "    for md_path in repo_path.rglob(\"*.md\"):\n",
    "        if md_path.name.lower() == \"readme.md\":\n",
    "            continue\n",
    "        try:\n",
    "            content = md_path.read_text(encoding=\"utf-8\").strip()\n",
    "            if 50 < len(content) < 5000:\n",
    "                chunks.append(Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\n",
    "                        \"source\": str(md_path),\n",
    "                        \"file_ext\": \"markdown\",\n",
    "                        \"type\": \"markdown\",\n",
    "                        \"name\": md_path.name,\n",
    "                        \"lines\": f\"1-{content.count(chr(10)) + 1}\"\n",
    "                    }\n",
    "                ))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # 3. Code and misc files\n",
    "    for filepath in repo_path.rglob(\"*.*\"):\n",
    "        if is_low_value_file(filepath):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            suffix = filepath.suffix.lower()\n",
    "\n",
    "            # 3a. Python files\n",
    "            if suffix == \".py\":\n",
    "                code = filepath.read_text(encoding=\"utf-8\")\n",
    "                tree = ast.parse(code)\n",
    "\n",
    "                mod_doc = ast.get_docstring(tree)\n",
    "                if mod_doc and 50 < len(mod_doc) < 5000:\n",
    "                    chunks.append(Document(\n",
    "                        page_content=mod_doc,\n",
    "                        metadata={\n",
    "                            \"source\": str(filepath),\n",
    "                            \"file_ext\": \"code\",\n",
    "                            \"type\": \"module_docstring\",\n",
    "                            \"name\": filepath.name,\n",
    "                            \"lines\": f\"1-{code.count(chr(10)) + 1}\"\n",
    "                        }\n",
    "                    ))\n",
    "\n",
    "                for node in tree.body:\n",
    "                    if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "                        content = ast.get_source_segment(code, node)\n",
    "                        if content and 50 < len(content) < 5000:\n",
    "                            chunks.append(Document(\n",
    "                                page_content=content,\n",
    "                                metadata={\n",
    "                                    \"source\": str(filepath),\n",
    "                                    \"file_ext\": \"code\",\n",
    "                                    \"type\": type(node).__name__.lower(),\n",
    "                                    \"name\": node.name,\n",
    "                                    \"lines\": f\"{node.lineno}-{getattr(node, 'end_lineno', node.lineno)}\"\n",
    "                                }\n",
    "                            ))\n",
    "\n",
    "                        doc = ast.get_docstring(node)\n",
    "                        if doc and 50 < len(doc) < 5000:\n",
    "                            chunks.append(Document(\n",
    "                                page_content=doc,\n",
    "                                metadata={\n",
    "                                    \"source\": str(filepath),\n",
    "                                    \"file_ext\": \"code\",\n",
    "                                    \"type\": f\"{type(node).__name__.lower()}_docstring\",\n",
    "                                    \"name\": node.name,\n",
    "                                    \"lines\": f\"{node.lineno}-{getattr(node, 'end_lineno', node.lineno)}\"\n",
    "                                }\n",
    "                            ))\n",
    "\n",
    "            # 3b. Notebooks\n",
    "            elif suffix == \".ipynb\":\n",
    "                nb = nbformat.read(filepath, as_version=4)\n",
    "                for i, cell in enumerate(nb.cells):\n",
    "                    if cell.cell_type in (\"markdown\", \"code\"):\n",
    "                        content = cell.source.strip()\n",
    "                        if 50 < len(content) < 5000:\n",
    "                            chunks.append(Document(\n",
    "                                page_content=content,\n",
    "                                metadata={\n",
    "                                    \"source\": str(filepath),\n",
    "                                    \"file_ext\": \"code\",\n",
    "                                    \"type\": f\"{cell.cell_type}_cell\",\n",
    "                                    \"name\": f\"{filepath.name} - cell {i}\",\n",
    "                                    \"lines\": f\"cell_{i}\"\n",
    "                                }\n",
    "                            ))\n",
    "\n",
    "            # 3c. Other code/text files\n",
    "            else:\n",
    "                code = filepath.read_text(encoding=\"utf-8\")\n",
    "                if 50 < len(code) < 5000:\n",
    "                    chunks.append(Document(\n",
    "                        page_content=code,\n",
    "                        metadata={\n",
    "                            \"source\": str(filepath),\n",
    "                            \"file_ext\": \"code\",\n",
    "                            \"type\": suffix,\n",
    "                            \"name\": filepath.name,\n",
    "                            \"lines\": f\"1-{code.count(chr(10)) + 1}\"\n",
    "                        }\n",
    "                    ))\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Optional FAISS index creation\n",
    "    # embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    # vectordb = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "    # vectordb.save_local(index_dir)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7682d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = \"https://github.com/adarshlearnngrow/StepUpYourCareer.AI\"\n",
    "repo_path = clone_repo(repo_url)\n",
    "\n",
    "# 1Ô∏è‚É£ Build the FAISS DB from your repo\n",
    "chunks = extract_all_chunks_to_faiss(repo_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa42dd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55285b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_chunk(text: str, model: str = \"gpt-3.5-turbo-0125\") -> dict:\n",
    "    \"\"\"\n",
    "    Classify a chunk into one or more documentation sections.\n",
    "    Returns: dict with {\"sections\": [...], \"rationale\": ..., \"tags\": [...]}\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "\n",
    "    layout = [\n",
    "        \"Project Overview\", \"Objective & Scope\", \"System Architecture\",\n",
    "        \"Tech Stack\", \"Installation & Setup\", \"Usage Instructions\",\n",
    "        \"API Documentation\", \"Others\"\n",
    "    ]\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an expert technical writer. Given a code or text chunk, \"\n",
    "        \"identify ALL documentation sections it may contribute to, based on the following layout:\\n\\n\"\n",
    "        + \"\\n\".join(f\"- {s}\" for s in layout) +\n",
    "        \"\\n\\nOutput must be in JSON format with these fields:\\n\"\n",
    "        \"- sections: a list of one or more relevant section names\\n\"\n",
    "        \"- rationale: 1‚Äì3 sentence explanation of why these sections are appropriate\\n\"\n",
    "        \"- tags: 5‚Äì10 keywords from the chunk (e.g., FastAPI, endpoint, config, Docker, class, train loop)\\n\\n\"\n",
    "        \"Be analytical. If a chunk helps define a function and also contains setup instructions, include both.\"\n",
    "    )\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": text[:16_000]},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "    import json\n",
    "    try:\n",
    "        return json.loads(resp.choices[0].message.content.strip())\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"sections\": [\"Others\"],\n",
    "            \"rationale\": \"Failed to parse response\",\n",
    "            \"tags\": []\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d3c6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in chunks:\n",
    "    label = multi_label_chunk(doc.page_content)\n",
    "    doc.metadata[\"sections\"] = label[\"sections\"]        # <-- fix here\n",
    "    doc.metadata[\"tags\"] = label[\"tags\"]\n",
    "    doc.metadata[\"rationale\"] = label[\"rationale\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'tmp_repo\\\\README.md', 'file_ext': 'text', 'type': 'readme', 'name': 'README.md', 'lines': '1-29', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='# StepUpYourCareer.ai: Elevate Your Future\\n\\nAn AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\\n\\n### Link to the website: https://stepupyourcareer.streamlit.app/\\n\\n---\\n\\n## Problem\\n\\nGraduates often leave university with degrees but **lack clarity on what employers actually expect**. They spend months applying for jobs, facing rejections without knowing **what skills they‚Äôre missing** or **how to upskill efficiently**.\\n\\n---\\n\\n## Solution\\n\\n**StepUpYourCareer.ai** transforms your resume into a personalized upskilling journey.\\n\\n- **Skill Gap Analyzer**: Extracts skills from your resume and compares them to your target role\\n- **Action Plan Generator**: Recommends curated online courses and resources for each missing skill\\n- **Mentor Matching**: Clusters users and mentors using K-Means to connect you with experts in your domain\\n\\n---\\n\\n![Notes_250516_042908_1](https://github.com/user-attachments/assets/a42216a8-e04c-4335-aad7-d56a61cc873b)\\n\\n![Notes_250516_042908_4](https://github.com/user-attachments/assets/ba3b34ec-57ec-4bf5-906a-84af82342b8b)\\n\\n![Notes_250516_042908_3](https://github.com/user-attachments/assets/4b7e5f11-7923-427c-be95-cbcd7d919c5b)'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 0', 'lines': 'cell_0', 'sections': ['Others'], 'tags': ['Google Colab', 'notebook', 'Clustering', 'Mentor Model', 'Training'], 'rationale': 'This chunk is a link to a Google Colab notebook for training a clustering mentor model, which does not fit into any specific documentation section.'}, page_content='<a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUpYourCareer.AI/blob/Clustering/ClusteringMentorModelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 2', 'lines': 'cell_2', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content=\"from openai import OpenAI\\nimport json\\nimport time\\nfrom google.colab import userdata\\nimport pandas as pd\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.metrics import calinski_harabasz_score\\nfrom sklearn.metrics import silhouette_score\\nimport joblib\\nfrom sklearn.manifold import TSNE\\nimport matplotlib.patches as mpatches\\nimport os\\npd.set_option('display.max_colwidth', None)\"),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 3', 'lines': 'cell_3', 'sections': ['Installation & Setup', 'Usage Instructions'], 'tags': ['OpenAI', 'API key', 'client', 'userdata', 'setup', 'interact', 'API'], 'rationale': 'This code chunk involves setting up the OpenAI client with an API key, making it relevant for both the Installation & Setup section (setting up the client) and the Usage Instructions section (using the client to interact with the OpenAI API).'}, page_content='client = OpenAI(api_key=userdata.get(\"Open_AI_API_KEY\"))'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 4', 'lines': 'cell_4', 'sections': ['Objective & Scope', 'Others'], 'tags': ['Mentors', 'skills', 'expertise', 'generate'], 'rationale': \"This chunk defines the objective of generating mentors with specific skills, falling under the project's scope. It does not fit into any specific technical documentation section.\"}, page_content='## Prompt to generate Mentors with skills of experties'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 5', 'lines': 'cell_5', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='def generate_mentor_prompt(role, tech_skills, n=10):\\n    prompt = f\"\"\"\\nYou are an assistant helping to create a database of expert mentors.\\n\\nGenerate {n} mentor profiles for the role: \"{role}\".\\n\\nEach mentor should have:\\n- A realistic name\\n- A short professional bio (1‚Äì2 sentences)\\n- A list of 5‚Äì7 technical skills (from this list but make sure it the wording are same or atleast close to it, because we will be doing predictions on it later):\\n  {\\', \\'.join(tech_skills)}\\n\\nReturn the output in this JSON format:\\n[\\n  {{\\n    \"name\": \"Mentor Name\",\\n    \"bio\": \"Short mentor bio.\",\\n    \"linkedin_id\": \"Mentor LinkedIn ID\",\\n    \"technical_skills\": [\"skill1\", \"skill2\", ...]\\n  }},\\n  ...\\n]\\n\"\"\"\\n    return prompt\\n\\n# Load role + skill data\\nwith open(\"/content/sample_data/role_skills.json\") as f:\\n    roles_data = json.load(f)\\n\\n# Collection\\nall_mentors = []\\nmentor_counter = 1\\n\\n# Generate mentors for each role\\nfor role_info in roles_data:\\n    role = role_info[\"role\"]\\n    tech_skills = role_info[\"technical_skills\"]\\n\\n    prompt = generate_mentor_prompt(role, tech_skills, n=25)\\n\\n    try:\\n        response = client.chat.completions.create(\\n            model=\"gpt-3.5-turbo\",\\n            messages=[{\"role\": \"user\", \"content\": prompt}],\\n            temperature=0.7\\n        )\\n\\n        raw_output = response.choices[0].message.content.strip()\\n        mentors = json.loads(raw_output)\\n\\n        for mentor in mentors:\\n            mentor[\"mentor_id\"] = f\"M{mentor_counter:04d}\"\\n            mentor[\"role\"] = role\\n            mentor_counter += 1\\n\\n        all_mentors.extend(mentors)\\n        print(f\"Added {len(mentors)} mentors for role: {role}\")\\n\\n    except Exception as e:\\n        print(f\"Error processing role {role}: {e}\")\\n\\n# ‚úÖ Save to JSON\\nwith open(\"generated_mentors.json\", \"w\") as f:\\n    json.dump(all_mentors, f, indent=2)\\n\\nprint(f\"\\\\n‚úÖ All mentor profiles saved to \\'generated_mentors.json\\' ({len(all_mentors)} total).\")'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 6', 'lines': 'cell_6', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='mentors_final_data = pd.read_json(\"generated_mentors.json\")\\nmentors_final_data.set_index(\"mentor_id\", inplace=True)\\nmentors_final_data.head(5)'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 8', 'lines': 'cell_8', 'sections': ['Usage Instructions', 'Others'], 'tags': ['MultiLabelBinarizer', 'fit_transform', 'joblib', 'DataFrame', 'technical skills', 'transform', 'save', 'index'], 'rationale': 'The code chunk demonstrates how to use the MultiLabelBinarizer to transform technical skills data and save the model using joblib. It also creates a DataFrame with the transformed data.'}, page_content='mlb = MultiLabelBinarizer()\\nskills_matrix = mlb.fit_transform(mentors_final_data[\\'technical_skills\\'])\\njoblib.dump(mlb, \"mlb.joblib\")\\nskills_df = pd.DataFrame(skills_matrix, columns=mlb.classes_, index=mentors_final_data.index)\\nskills_df.head(5)'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 9', 'lines': 'cell_9', 'sections': ['Usage Instructions'], 'tags': ['KMean', 'model', 'cluster', 'fitting', '100 times'], 'rationale': \"This chunk provides information on how to use the code to fit a KMean model with a range of cluster k and run it for 100 times, making it suitable for the 'Usage Instructions' section.\"}, page_content='### Fitting a KMean model with range of cluster k and ran for 100 times to be certain.'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 10', 'lines': 'cell_10', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='k_val = np.arange(10, 30)\\nbest_k = None\\nbest_score = -1\\nshilloutte_scores = []\\ninertias = []\\nch_indexs = []\\n\\nfor k in k_val:\\n    temp_sil_scores = []\\n    temp_ch_scores = []\\n    temp_inertias = []\\n\\n    for run in range(100):  # 100 is heavy; reduce to 5 or 10 for dev\\n        kmeans = KMeans(n_clusters=k, random_state=run, n_init=\\'auto\\')\\n        labels = kmeans.fit_predict(skills_df)\\n\\n        sil_score = silhouette_score(skills_df, labels)\\n        ch_index = calinski_harabasz_score(skills_df, labels)\\n\\n        temp_sil_scores.append(sil_score)\\n        temp_ch_scores.append(ch_index)\\n        temp_inertias.append(kmeans.inertia_)\\n\\n    # Average over all runs\\n    avg_sil = np.mean(temp_sil_scores)\\n    avg_ch = np.mean(temp_ch_scores)\\n    avg_inertia = np.mean(temp_inertias)\\n\\n    shilloutte_scores.append(avg_sil)\\n    ch_indexs.append(avg_ch)\\n    inertias.append(avg_inertia)\\n\\n    if avg_sil > best_score:\\n        best_score = avg_sil\\n        best_k = k\\n\\nprint(f\"‚úÖ Best K = {best_k} with silhouette score = {best_score:.4f}\")\\n\\n# üìà Plot all 3 metrics\\nplt.figure(figsize=(15, 4))\\n\\nplt.subplot(1, 3, 1)\\nplt.plot(k_val, inertias, marker=\\'o\\')\\nplt.title(\"Elbow Plot (Inertia)\")\\nplt.xlabel(\"Number of Clusters (K)\")\\nplt.ylabel(\"Inertia\")\\nplt.grid(True)\\n\\nplt.subplot(1, 3, 2)\\nplt.plot(k_val, shilloutte_scores, marker=\\'s\\', color=\\'green\\')\\nplt.title(\"Silhouette Score\")\\nplt.xlabel(\"Number of Clusters (K)\")\\nplt.ylabel(\"Score\")\\nplt.grid(True)\\n\\nplt.subplot(1, 3, 3)\\nplt.plot(k_val, ch_indexs, marker=\\'^\\', color=\\'purple\\')\\nplt.title(\"Calinski-Harabasz Index\")\\nplt.xlabel(\"Number of Clusters (K)\")\\nplt.ylabel(\"Score\")\\nplt.grid(True)\\n\\nplt.tight_layout()\\nplt.show()'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 12', 'lines': 'cell_12', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='best_k = 29\\nkmeans_final = KMeans(n_clusters=best_k, random_state=42, n_init=\\'auto\\')\\nmentors_final_data[\"cluster\"] = kmeans_final.fit_predict(skills_df)\\n\\n# Mount Google Drive\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive\\')\\n\\n\\n# Define path to save\\nsave_path = \"/content/drive/My Drive/saved_models\"\\nos.makedirs(save_path, exist_ok=True)\\n\\n# Save your scikit-learn KMeans model\\njoblib.dump(mlb, os.path.join(save_path,\"fitted_vectorizer.pkl\"))\\njoblib.dump(kmeans_final, os.path.join(save_path, \"mentor_clustering_model.pkl\"))\\n\\nprint(\"KMeans model saved to Google Drive!\")'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 14', 'lines': 'cell_14', 'sections': ['Usage Instructions', 'Others'], 'tags': ['t-SNE', 'clustering algorithm', 'skills', 'roles', 'visualization'], 'rationale': \"This code chunk provides guidance on using t-SNE for visualizing clustering results, which falls under the 'Usage Instructions' section. It also introduces a specific analysis task related to clustering and skills/roles, which can be considered as a miscellaneous topic.\"}, page_content='### Using TSNE to see if the clustering algorithm is grouping based on skills or based on roles'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 15', 'lines': 'cell_15', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='tsne = TSNE(n_components=2, perplexity=30, random_state=42)\\ntsne_result = tsne.fit_transform(skills_df.values)\\n\\nplt.figure(figsize=(16, 6))  # one wide figure with 2 subplots\\n\\n# Subplot 1 ‚Äî using cluster labels\\nplt.subplot(1, 2, 1)\\nplt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=mentors_final_data[\"cluster\"], cmap=\\'tab10\\')\\nplt.title(\"Mentor Clusters by KMeans\")\\nplt.xlabel(\"TSNE Dimension 1\")\\nplt.ylabel(\"TSNE Dimension 2\")\\n#plt.(label=\\'Cluster\\')\\nplt.grid(True)\\n\\nrole_mapping = {role: idx for idx, role in enumerate(mentors_final_data[\"role\"].unique())}\\nrole_labels = mentors_final_data[\"role\"].map(role_mapping).values\\nplt.subplot(1, 2, 2)\\nplt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=role_labels, cmap=\\'tab10\\')\\nplt.title(\"Mentor Labels by Target Role\")\\nplt.xlabel(\"TSNE Dimension 1\")\\nplt.ylabel(\"TSNE Dimension 2\")\\n#plt.colorbar(label=\\'Role Label\\')\\nplt.grid(True)\\n\\nplt.tight_layout()\\nplt.show()'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 16', 'lines': 'cell_16', 'sections': ['Project Overview', 'Objective & Scope'], 'tags': ['clustering', 'skills', 'roles', 'overlapping clusters'], 'rationale': 'This chunk provides a high-level insight into the project by discussing the clustering of skills within roles and the presence of overlapping clusters, indicating the objective and scope of the project.'}, page_content='### Clustering happeining on skills cause within each role there are still overlapping clusters, means skills are common within each roles'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 18', 'lines': 'cell_18', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='#predicting on a student\\n\\n# Load student skill gap\\nstudent_data = pd.read_json(\"skill_gap_analysis.json\")\\nskill_gap = student_data.iloc[np.random.randint(1)][\\'technical_skill_gap\\']\\n\\nskill_gap = [s.strip() for s in skill_gap.split(\",\")]\\nskill_gap\\n\\n# Ensure mlb is already fitted on your mentor skill data\\nmlb.transform([skill_gap])'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 19', 'lines': 'cell_19', 'sections': ['Usage Instructions', 'Tech Stack'], 'tags': ['predict', 'kmeans', 'mlb', 'transform', 'scikit-learn', 'machine learning', 'prediction'], 'rationale': \"This code snippet shows how to make predictions using a trained KMeans model, which falls under Usage Instructions. It also indicates the use of scikit-learn's KMeans implementation, relevant for the Tech Stack section.\"}, page_content='prediction = kmeans_final.predict(mlb.transform([skill_gap]))'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\ClusteringMentorModelTraining.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'ClusteringMentorModelTraining.ipynb - cell 21', 'lines': 'cell_21', 'sections': ['Usage Instructions'], 'tags': ['mentors_final_data', 'cluster', 'prediction', 'filter', 'function', 'feature'], 'rationale': 'This code chunk provides instructions on how to use a specific function or feature to filter mentors based on a predicted cluster.'}, page_content='mentors_final_data[mentors_final_data[\"cluster\"] == prediction[0]][[\\'name\\', \\'bio\\',\\'linkedin_id\\', \\'technical_skills\\']]'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 0', 'lines': 'cell_0', 'sections': ['Others'], 'tags': ['Google Colab', 'notebook', 'job description', 'manipulation'], 'rationale': 'This chunk is a hyperlink to a Google Colab notebook for job description manipulation, which does not fit into any specific documentation section.'}, page_content='<a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Job_Description_JD_Manupulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 2', 'lines': 'cell_2', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='from google.colab import files\\n\\nuploaded = files.upload()\\n\\nfor fn in uploaded.keys():\\n  print(\\'User uploaded file \"{name}\" with length {length} bytes\\'.format(\\n      name=fn, length=len(uploaded[fn])))'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 3', 'lines': 'cell_3', 'sections': ['Usage Instructions'], 'tags': ['pandas', 'read_csv', 'query', 'filter', 'select', 'dataset', 'job descriptions'], 'rationale': 'This code chunk demonstrates how to filter and select specific job descriptions from a processed dataset, which can be considered as a part of the usage instructions for utilizing the dataset effectively.'}, page_content='jobs_desc = pd.read_csv(\"JobsDatasetProcessed.csv\")\\nreq_jobs_desc = jobs_desc.query(\"Query in [\\'Artificial Intelligence\\', \\'Business Analyst\\', \\'Business Intelligence Analyst\\', \\'Data Analyst\\', \\'Machine Learning\\']\")\\nreq_jobs_desc = req_jobs_desc[[\\'Query\\', \\'Description\\']]'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 4', 'lines': 'cell_4', 'sections': ['Usage Instructions'], 'tags': ['DataFrame', 'update', 'query', 'data manipulation', 'Pandas'], 'rationale': 'This code snippet provides instructions on how to update a query in a DataFrame, which can be considered a part of the usage instructions for manipulating data within the project.'}, page_content=\"req_jobs_desc.loc[req_jobs_desc['Query'] == 'Artificial Intelligence', 'Query'] = 'AI Engineer'\\nreq_jobs_desc\"),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 5', 'lines': 'cell_5', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='from google.colab import sheets\\nsheet = sheets.InteractiveSheet(df=req_jobs_desc)'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 6', 'lines': 'cell_6', 'sections': ['Usage Instructions'], 'tags': ['files', 'upload', 'print', 'length', 'bytes'], 'rationale': 'This code chunk provides instructions on how to handle and display uploaded files.'}, page_content='uploaded = files.upload()\\n\\nfor fn in uploaded.keys():\\n  print(\\'User uploaded file \"{name}\" with length {length} bytes\\'.format(\\n      name=fn, length=len(uploaded[fn])))'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 7', 'lines': 'cell_7', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='sim_resumes = pd.read_json(\"all_roles_student_resumes.json\")'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 8', 'lines': 'cell_8', 'sections': ['Usage Instructions'], 'tags': ['pandas', 'DataFrame', 'update', 'column', 'data manipulation'], 'rationale': 'This code chunk demonstrates how to update a column in a DataFrame using pandas. It can be included in the Usage Instructions section to show users how to manipulate data within the application.'}, page_content=\"sim_resumes.loc[sim_resumes['target_role'] == 'Artificial Intelligence', 'target_role'] = 'AI Engineer'\"),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 9', 'lines': 'cell_9', 'sections': ['Usage Instructions'], 'tags': ['to_json', 'JSON', 'save', 'simulation', 'resumes', 'orient', 'records', 'lines'], 'rationale': 'This code snippet provides instructions on how to save simulation resumes to a JSON file, making it relevant for the Usage Instructions section.'}, page_content=\"sim_resumes.to_json('sim_resume.json', orient='records', lines=False)\"),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 0', 'lines': 'cell_0', 'sections': ['Others'], 'tags': ['Colab', 'research', 'notebook', 'Google Colab', 'link'], 'rationale': 'This chunk provides a link to open the notebook in Google Colab, which is not directly related to any specific documentation section.'}, page_content='<a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 2', 'lines': 'cell_2', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content=\"# !pip install PyPDF2 openai\\nimport openai\\nimport json\\nimport time\\nimport re\\nfrom openai import OpenAI\\nfrom google.colab import userdata\\nimport pandas as pd\\npd.set_option('display.max_colwidth', None)\\nfrom PyPDF2 import PdfReader\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nimport numpy as np\"),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 3', 'lines': 'cell_3', 'sections': ['Installation & Setup', 'Usage Instructions'], 'tags': ['OpenAI', 'api_key', 'userdata', 'setup', 'client', 'API'], 'rationale': 'This code chunk involves setting up the OpenAI client by providing the API key, making it relevant for both Installation & Setup and Usage Instructions sections.'}, page_content='client = OpenAI(api_key=userdata.get(\"openai_key\"))'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 5', 'lines': 'cell_5', 'sections': ['Others'], 'tags': ['Artificial Intelligence', 'Business Analyst', 'Business Intelligence Analyst', 'Data Analyst', 'Machine Learning'], 'rationale': 'This chunk provides a list of roles related to artificial intelligence and data analysis, which can be considered as additional information for readers but does not fit into any specific documentation section.'}, page_content='roles = [\\n    \"Artificial Intelligence\",\\n    \"Business Analyst\",\\n    \"Business Intelligence Analyst\",\\n    \"Data Analyst\",\\n    \"Machine Learning\"\\n]'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 7', 'lines': 'cell_7', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='def generate_student_resume(role: str):\\n    prompt = f\"\"\"\\nYou are generating a **realistic and anonymized resume** for a computer science student or recent graduate (0‚Äì2 years of experience) applying for a role as a {role}.\\n\\nReturn strictly valid JSON in the following format:\\n{{\\n  \"name\": \"Candidate_<ID>\",\\n  \"education\": \"<Degree, Masked University (e.g., \\'Top Engineering Institute\\'), Graduation Years>\",\\n  \"work_experience\": [\\n    {{\\n      \"role\": \"<Internship or research title>\",\\n      \"company\": \"<Realistic but anonymized organization (e.g., \\'NeuroTech AI\\', \\'InsightSoft Labs\\')>\",\\n      \"duration\": \"<Month Year ‚Äì Month Year>\",\\n      \"description\": \"Describe the responsibilities in a detailed, narrative style. Mention the purpose of the project, specific tasks completed, tools/technologies used, and measurable impact. Be authentic ‚Äî include dataset sizes, model names, APIs, or product features if relevant.\"\\n    }},\\n    {{\\n      \"role\": \"<Optional second experience (lab assistant, part-time dev, open-source contributor)>\",\\n      \"company\": \"<Another anonymized organization (e.g., \\'Top Tech University - DataLab\\')>\",\\n      \"duration\": \"<Month Year ‚Äì Month Year>\",\\n      \"description\": \"Follow the same format: outcome-focused, rich in tech and context. Avoid vague phrasing.\"\\n    }}\\n  ],\\n  \"personal_projects\": [\\n    {{\\n      \"title\": \"<Unique, interesting project title>\",\\n      \"description\": \"Explain the project‚Äôs motivation (e.g. coursework, curiosity, hackathon), what problem it solved, what tech was used, and the result. Include metrics if applicable. Avoid generic projects like \\'movie recommender\\'.\"\\n    }},\\n    {{\\n      \"title\": \"<Second project (can be unrelated to the role)>\",\\n      \"description\": \"Still provide depth. For example, a photography app, social impact tool, or game with real features. Mention full-stack tools or libraries used.\"\\n    }}\\n  ],\\n   \"technical_skills\": [\"<Realistic tech skills: some aligned, some adjacent>\"],\\n   \"soft_skills\": [\"<Soft skills like teamwork, leadership, communication, etc.>\"]\\n}}\\n\\nSTRICT INSTRUCTIONS:\\n- **No markdown**, **no explanations**, only valid, well-formatted JSON.\\n- **Do not reuse phrases** like ‚Äúworked with a team‚Äù or ‚Äúimproved accuracy.‚Äù\\n- **Never use placeholder names** like Tech_Startup_123. Instead, use fictional but plausible names like ‚ÄúCortexAI‚Äù or ‚ÄúNuvem Data.‚Äù\\n- Use **varied and creative projects** ‚Äî not all should be recommendation systems!\\n- Projects can be from coursework, hackathons, personal exploration, or clubs\\n- Leave **some skill gaps** compared to what a real job would require\\n- Descriptions must sound like they were written by a strong student applying to a competitive job ‚Äî technically sharp, reflective, and specific.\\n- You may simulate imperfections (e.g., slightly over-descriptive soft skills or overuse of buzzwords) occasionally for realism, but keep overall quality high.\\n\"\"\"\\n\\n    response = client.chat.completions.create(\\n        model=\"gpt-4o-mini\",\\n        messages=[{\"role\": \"user\", \"content\": prompt}],\\n        temperature=0.8\\n    )\\n    return response.choices[0].message.content.strip()\\n\\nresumes = []\\n\\nfor role in roles:\\n    print(f\"Generating resumes for role: {role}\")\\n    for i in range(10):\\n        try:\\n            resume_json = generate_student_resume(role=role)\\n            resume_dict = json.loads(resume_json)\\n            resume_dict[\"target_role\"] = role\\n            resumes.append(resume_dict)\\n            print(f\"Resume {i+1} for {role}\")\\n            time.sleep(1)\\n        except Exception as e:\\n            print(f\"Error at resume {i+1} for {role}: {e}\")\\n\\n# Save all resumes to a JSON file\\nwith open(\"all_roles_student_resumes.json\", \"w\", encoding=\"utf-8\") as f:\\n    json.dump(resumes, f, indent=2, ensure_ascii=False)\\n\\nprint(\"All resumes saved to all_roles_student_resumes.json\")'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 9', 'lines': 'cell_9', 'sections': ['Installation & Setup'], 'tags': ['open', 'json', 'load', 'csv', 'read_csv', 'pandas', 'data', 'files', 'setup'], 'rationale': 'This code chunk involves loading data from JSON and CSV files, which is part of the setup process for the project.'}, page_content='with open(\"all_roles_student_resumes.json\", \"r\") as f:\\n    resumes = json.load(f)\\n\\njobs_df = pd.read_csv(\"req_job_desc.csv\")'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 11', 'lines': 'cell_11', 'sections': ['Usage Instructions'], 'tags': ['function', 'resume', 'job', 'skills', 'education', 'work experience'], 'rationale': 'These functions provide instructions on how to use them to summarize resumes and job descriptions.'}, page_content='def summarize_resume(resume):\\n    tech_skills = \", \".join(resume.get(\"technical_skills\", []))\\n    soft_skills = \", \".join(resume.get(\"soft_skills\", []))\\n    parts = []\\n    if resume.get(\"education\"):\\n        parts.append(f\"Education: {resume[\\'education\\']}\")\\n    if resume.get(\"work_experience\"):\\n        roles = [we.get(\"role\") for we in resume[\"work_experience\"] if we.get(\"role\")]\\n        if roles:\\n            parts.append(\"Experience roles: \" + \", \".join(roles))\\n    if tech_skills:\\n        parts.append(\"Technical Skills: \" + tech_skills)\\n    if soft_skills:\\n        parts.append(\"Soft Skills: \" + soft_skills)\\n    return \" | \".join(parts)\\n\\ndef summarize_job(job):\\n    title = job.get(\"Job Title\", \"Job\")\\n    it_skills = job.get(\"IT Skills\", \"\")\\n    soft_skills = job.get(\"Soft Skills\", \"\")\\n    return f\"Job Title: {title} | Required Technical Skills: {it_skills} | Required Soft Skills: {soft_skills}\"'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 12', 'lines': 'cell_12', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='### Printing 120 job descriptions for each role (Total 600)'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 14', 'lines': 'cell_14', 'sections': ['Objective & Scope'], 'tags': ['skills', 'required', 'technical', 'soft skills', 'roles'], 'rationale': 'This chunk describes the objective of extracting common required technical and soft skills for each role, setting the scope of the project.'}, page_content='### Extracting common required technical and soft skills required for each role.'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 15', 'lines': 'cell_15', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='jobs_df = pd.read_csv(\"req_job_desc.csv\")\\n\\n# Group by target role\\ngrouped_roles = jobs_df.groupby(\"Query\")\\n\\ndef extract_skills_from_descriptions(role, descriptions):\\n    combined_text = \"\\\\n\\\\n---\\\\n\\\\n\".join(descriptions)\\n\\n    prompt = f\"\"\"\\n      You are a highly skilled AI career advisor. You are given a set of job descriptions for the role of \"{role}\".\\n\\n      Your task is to extract the **common transferable skills** required across these jobs ‚Äî categorize them as:\\n      1. Technical Skills\\n      2. Soft Skills\\n\\n      Avoid any industry-specific or domain-specific skills (e.g., \"healthcare compliance\", \"lab equipment use\", \"insurance claim processing\"). Focus only on **transferable, job-agnostic skills**.\\n\\n      Output must be in strict JSON format like this:\\n      {{\\n        \"role\": \"{role}\",\\n        \"technical_skills\": [\"skill1\", \"skill2\", ...],\\n        \"soft_skills\": [\"skillA\", \"skillB\", ...]\\n      }}\\n\\n      Here are the job descriptions:\\n      {combined_text}\\n      \"\"\"\\n\\n    try:\\n        response = client.chat.completions.create(\\n            model=\"gpt-4o-mini\",\\n            messages=[\\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant for extracting transferable skills.\"},\\n                {\"role\": \"user\", \"content\": prompt}\\n            ],\\n            temperature=0.2\\n        )\\n\\n        raw_output = response.choices[0].message.content.strip()\\n        if raw_output.startswith(\"```json\"):\\n            raw_output = raw_output[7:]\\n        if raw_output.endswith(\"```\"):\\n            raw_output = raw_output[:-3]\\n\\n        return json.loads(raw_output)\\n\\n    except Exception as e:\\n        print(f\"Error for role \\'{role}\\': {e}\")\\n        return {\\n            \"role\": role,\\n            \"technical_skills\": [],\\n            \"soft_skills\": []\\n        }\\n\\n# Run for all roles\\nresults = []\\nfor role, group in grouped_roles:\\n    print(f\"Extracting skills for role: {role}\")\\n    descriptions = group[\"Description\"].dropna().tolist()\\n    if not descriptions:\\n        continue\\n    skill_summary = extract_skills_from_descriptions(role, descriptions)\\n    results.append(skill_summary)\\n    time.sleep(1)\\n\\n# Save to files\\ndf_out = pd.DataFrame(results)\\ndf_out.to_csv(\"role_transferable_skills.csv\", index=False)\\nwith open(\"role_transferable_skills.json\", \"w\") as f:\\n    json.dump(results, f, indent=2)\\n\\nprint(\"\\\\n Skill extraction complete. Files saved: role_transferable_skills.csv and .json\")'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 16', 'lines': 'cell_16', 'sections': ['Others'], 'tags': ['skills', 'role', 'common', 'file', 'required', 'particular'], 'rationale': \"This chunk does not fit into any specific documentation section but can be included under 'Others' as it contains information that does not directly fall under any other category.\"}, page_content='### File containing all common skills required for a particular role'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 17', 'lines': 'cell_17', 'sections': ['Usage Instructions'], 'tags': ['open', 'json', 'load', 'print', 'file', 'resumes_data'], 'rationale': 'This code chunk demonstrates how to load and print JSON data from a file, which is essential for users to understand how to use the program.'}, page_content='with open(\"role_skills.json\", \"r\") as f:\\n    resumes_data = json.load(f)\\n\\nprint(json.dumps(resumes_data, indent=2))'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 18', 'lines': 'cell_18', 'sections': ['Objective & Scope'], 'tags': ['skill gaps', 'resumes', 'desired role'], 'rationale': 'This chunk introduces the specific objective of identifying skill gaps in simulated resumes, outlining the scope of the task.'}, page_content='### Identifying skill gaps in the simulated resumes based on desired role'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 19', 'lines': 'cell_19', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='# Load Files\\nwith open(\"sim_resume.json\", \"r\") as f:\\n    resumes = [json.loads(line) for line in f]\\n\\nwith open(\"role_skills.json\", \"r\") as f:\\n    raw_roles = json.load(f)\\nrole_skills = {r[\"role\"]: r for r in raw_roles}\\n\\n# Helper Functions\\ndef summarize_resume(resume):\\n    \"\"\"Summarize fields from a student resume.\"\"\"\\n    summary = []\\n    if \"target_role\" in resume:\\n        summary.append(f\"Target Role: {resume[\\'target_role\\']}\")\\n    if \"education\" in resume:\\n        summary.append(f\"Education: {resume[\\'education\\']}\")\\n    if \"work_experience\" in resume:\\n        jobs = [w[\"role\"] for w in resume[\"work_experience\"] if \"role\" in w]\\n        if jobs:\\n            summary.append(\"Experience: \" + \", \".join(jobs))\\n    if \"technical_skills\" in resume:\\n        summary.append(\"Technical Skills: \" + \", \".join(resume[\"technical_skills\"]))\\n    if \"soft_skills\" in resume:\\n        summary.append(\"Soft Skills: \" + \", \".join(resume[\"soft_skills\"]))\\n    return \" | \".join(summary)\\n\\ndef generate_skill_gap(resume_text, expected_tech, expected_soft):\\n    \"\"\"Query OpenAI to get skill gaps and transferable skills.\"\"\"\\n    prompt = f\"\"\"\\nYou are a career advisor helping students identify skill gaps.\\n\\nCompare the student\\'s resume with the required skills below. Do 3 things:\\n\\n1. Identify missing **technical skills** from the list that are not in the resume.\\n2. Identify missing **soft skills** from the list.\\n3. Suggest **transferable skills** from the resume that could help the student learn the missing technical skills.\\n\\nReturn valid JSON with this structure:\\n{{\\n  \"technical_skill_gaps\": [...],\\n  \"soft_skill_gaps\": [...],\\n  \"transferable_skills\": [...]\\n}}\\n\\nIf a category is empty, return an empty list.\\nDo NOT explain or repeat anything. Just return clean JSON.\\n\\n---\\nResume:\\n{resume_text}\\n\\nRequired Technical Skills: {\", \".join(expected_tech)}\\nRequired Soft Skills: {\", \".join(expected_soft)}\\n\"\"\"\\n\\n    try:\\n        response = client.chat.completions.create(\\n            model=\"gpt-4o-mini\",\\n            messages=[\\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant for skill gap analysis.\"},\\n                {\"role\": \"user\", \"content\": prompt}\\n            ],\\n            temperature=0\\n        )\\n        result = response.choices[0].message.content.strip()\\n\\n        if result.startswith(\"```json\"):\\n            result = result[7:]\\n        if result.endswith(\"```\"):\\n            result = result[:-3]\\n\\n        parsed = json.loads(result)\\n        return (\\n            parsed.get(\"technical_skill_gaps\", []),\\n            parsed.get(\"soft_skill_gaps\", []),\\n            parsed.get(\"transferable_skills\", [])\\n        )\\n    except Exception as e:\\n        print(\"Error:\", e)\\n        return [], [], []\\n\\n# Run Analysis\\n\\nrecords = []\\n\\nfor idx, resume in enumerate(resumes):\\n    name = resume.get(\"name\", f\"Candidate_{idx}\")\\n    role = resume.get(\"target_role\", \"\").strip()\\n\\n    if not role or role not in role_skills:\\n        print(f\"[{name}] Skipped ‚Äî no target role or unknown role.\")\\n        continue\\n\\n    resume_summary = summarize_resume(resume)\\n    expected = role_skills[role]\\n    tech_skills = expected[\"technical_skills\"]\\n    soft_skills = expected[\"soft_skills\"]\\n\\n    print(f\"[{name}] ‚Üí Analyzing role: {role}\")\\n    tech_gap, soft_gap, transferable = generate_skill_gap(resume_summary, tech_skills, soft_skills)\\n\\n    records.append({\\n        \"name\": name,\\n        \"target_role\": role,\\n        \"resume_summary\": resume_summary,\\n        \"technical_skill_gap\": \", \".join(tech_gap),\\n        \"soft_skill_gap\": \", \".join(soft_gap),\\n        \"transferable_skills\": \", \".join(transferable)\\n    })\\n    time.sleep(1)\\n\\n# Save Output\\ndf = pd.DataFrame(records)\\ndf.to_csv(\"skill_gap_analysis.csv\", index=False)\\ndf.to_json(\"skill_gap_analysis.json\", orient=\"records\", indent=2)\\nprint(f\"\\\\n Done! Analyzed {len(records)} resumes and saved to CSV and JSON.\")'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 20', 'lines': 'cell_20', 'sections': ['Usage Instructions'], 'tags': ['Skill Gap Analysis', 'Functionality', 'upload', 'resume'], 'rationale': \"This chunk provides information on how to use the 'Skill Gap Analysis Functionality' by allowing users to upload their resume.\"}, page_content='### Skill Gap Analysis Functionality - allows user to upload their resume'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 21', 'lines': 'cell_21', 'sections': ['Objective & Scope', 'Tech Stack', 'Usage Instructions'], 'tags': ['resume', 'skill gap analysis', 'embedding', 'anonymize', 'PDF', 'GPT-4', 'JSON', 'pipeline', 'career advisor'], 'rationale': 'The code chunk defines functions for analyzing skill gaps in resumes, including extracting resume text, anonymizing it, retrieving examples, and generating skill gap reports. It also provides a detailed usage prompt for users on how to input resumes and required skills for analysis.'}, page_content='with open(\"skill_gap_analysis.json\", \"r\") as f:\\n    examples = json.load(f)\\n\\ndef get_embedding(text, model=\"text-embedding-ada-002\"):\\n    response = client.embeddings.create(input=[text], model=model)\\n    return response.data[0].embedding\\n\\nexample_texts = [\\n    f\"Resume: {ex[\\'resume_summary\\']} | Role: {ex[\\'target_role\\']}\" for ex in examples\\n]\\nexample_embeddings = [get_embedding(text) for text in example_texts]\\n\\nwith open(\"role_skills.json\", \"r\") as f:\\n    role_skills_list = json.load(f)\\n\\n# Convert list ‚Üí dict: { role_name: {technical_skills: [...], soft_skills: [...]} }\\nrole_skills = {\\n    entry[\"role\"]: {\\n        \"technical_skills\": entry.get(\"technical_skills\", []),\\n        \"soft_skills\": entry.get(\"soft_skills\", [])\\n    }\\n    for entry in role_skills_list if \"role\" in entry\\n}\\n\\n# Anonymize resume text\\ndef anonymize(text):\\n    return client.chat.completions.create(\\n        model=\"gpt-4o-mini\",\\n        messages=[\\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant that removes personal identifiers from resumes.\"},\\n            {\"role\": \"user\", \"content\": f\"Anonymize this resume:\\\\n\\\\n{text}\"}\\n        ],\\n        temperature=0\\n    ).choices[0].message.content.strip()\\n\\ndef extract_resume_text(pdf_path):\\n    reader = PdfReader(pdf_path)\\n    text = \"\\\\n\".join([page.extract_text() or \"\" for page in reader.pages])\\n    return text.strip()\\n\\ndef retrieve_examples(resume_text, target_role, k=3):\\n    query = f\"Resume: {resume_text} | Role: {target_role}\"\\n    query_embedding = get_embedding(query)\\n    sims = cosine_similarity([query_embedding], example_embeddings)[0]\\n    top_k_indices = sims.argsort()[-k:][::-1]\\n    return [examples[i] for i in top_k_indices]\\n\\ndef generate_skill_gap(resume_text, target_role, retrieved_examples, fallback_skills):\\n    examples_prompt = \"\\\\n\\\\n\".join([\\n        f\"Example for role {ex[\\'target_role\\']}:\\\\nResume: {ex[\\'resume_summary\\']}\\\\nSkill Gaps: tech={ex[\\'technical_skill_gap\\']}, soft={ex[\\'soft_skill_gap\\']}, transferable={ex[\\'transferable_skills\\']}\"\\n        for ex in retrieved_examples\\n    ])\\n\\n    expected_tech = fallback_skills.get(\"technical_skills\", [])\\n    expected_soft = fallback_skills.get(\"soft_skills\", [])\\n\\n    full_prompt = f\"\"\"\\nYou are a highly experienced career advisor. Below are real examples of skill gap analysis between student resumes and job requirements.\\n\\n## EXAMPLES\\n{examples_prompt}\\n\\n## TASK:\\n\\nNow, perform the same analysis on the following new resume.\\n\\n1. Read the student‚Äôs resume.\\n2. Compare it to the required skills.\\n3. Return:\\n   - Skills the student is missing (from the required lists).\\n   - Transferable skills the student has that help bridge gaps.\\n\\n## REQUIRED FORMAT ‚Äî Output valid JSON:\\n\\n{{\\n  \"technical_skill_gaps\": [list of missing technical skills],\\n  \"soft_skill_gaps\": [list of missing soft skills],\\n  \"transferable_skills\": [skills from the resume that can help learn missing ones]\\n}}\\n\\n‚ùå Do not explain anything. Do not repeat resume or skills. Just return the JSON.\\n‚ùå If no gaps, return empty lists.\\n\\n---\\n\\nüéØ Target Role: {target_role}\\nüìå Required Technical Skills: {\", \".join(expected_tech)}\\nüìå Required Soft Skills: {\", \".join(expected_soft)}\\n\\nüìÑ Resume:\\n{resume_text}\\n\"\"\"\\n\\n\\n    response = client.chat.completions.create(\\n        model=\"gpt-4o-mini\",\\n        messages=[\\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant for skill gap analysis.\"},\\n            {\"role\": \"user\", \"content\": full_prompt}\\n        ],\\n        temperature=0.0\\n    )\\n    raw = response.choices[0].message.content.strip()\\n    if raw.startswith(\"```json\"):\\n        raw = raw[7:]\\n    if raw.endswith(\"```\"):\\n        raw = raw[:-3]\\n    return json.loads(raw)\\n\\n# === Full pipeline function ===\\ndef analyze_uploaded_resume(pdf_path, target_role):\\n    resume_text = extract_resume_text(pdf_path)\\n    anonymized_resume = anonymize(resume_text)\\n    fallback_skills = role_skills.get(target_role, {})\\n    retrieved = retrieve_examples(anonymized_resume, target_role)\\n    result = generate_skill_gap(anonymized_resume, target_role, retrieved, fallback_skills)\\n    return {\\n        \"resume_text\": anonymized_resume,\\n        \"target_role\": target_role,\\n        **result\\n    }'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 22', 'lines': 'cell_22', 'sections': ['Usage Instructions', 'Others'], 'tags': ['Google Colab', 'files', 'upload', 'resume', 'analyze', 'input', 'output', 'JSON'], 'rationale': \"This code chunk provides usage instructions on how to upload a resume, specify a target role, and analyze the resume. It also falls under the 'Others' section as it involves file upload and processing.\"}, page_content='from google.colab import files\\n\\nuploaded = files.upload()\\npdf_path = list(uploaded.keys())[0]\\n\\ntarget_role = input(\"Enter your target role (e.g., \\'AI Engineer\\'): \").strip()\\n\\noutput = analyze_uploaded_resume(pdf_path, target_role)\\n\\nprint(json.dumps(output, indent=2))'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'markdown_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 23', 'lines': 'cell_23', 'sections': ['Project Overview'], 'tags': ['Action Plan', 'Testing', 'Candidates'], 'rationale': 'This chunk introduces the specific project task of generating an action plan for testing candidates.'}, page_content='### Action Plan Generation (Testing for 3 Candidates)'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb', 'file_ext': 'code', 'type': 'code_cell', 'name': 'Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 24', 'lines': 'cell_24', 'sections': ['Installation & Setup', 'Usage Instructions', 'API Documentation'], 'tags': ['pandas', 'read_csv', 'json', 'regex', 'API', 'DataFrame', 'iteration', 'JSONDecodeError', 'exception handling', 'time.sleep'], 'rationale': 'The code chunk includes functions for extracting JSON from a response, generating an action plan, and interacting with an API. It also demonstrates a usage example with a DataFrame iteration. This chunk can be used to explain how to set up the environment, provide instructions on how to use the functions, and document the API functionality.'}, page_content='df = pd.read_csv(\"skill_gap_analysis.csv\").head(3)\\n\\ndef extract_json_from_response(raw):\\n    \"\"\"Safely extract JSON object from LLM response using regex.\"\"\"\\n    match = re.search(r\"\\\\{[\\\\s\\\\S]*\\\\}\", raw)\\n    if match:\\n        try:\\n            return json.loads(match.group())\\n        except json.JSONDecodeError:\\n            return {}\\n    return {}\\n\\ndef generate_action_plan(tech_skills, soft_skills, transferable_skills):\\n    prompt = f\"\"\"\\nYou are a top-tier career advisor and learning coach. For each skill listed, recommend 2‚Äì3 diverse and high-quality, **REAL** learning resources with links.\\n\\nThe resources must be: genuinely helpful for mastering the skill\\n\\nResources may include:\\n- Online courses\\n- Popular Books with amazon links\\n- Practice Platforms (e.g. LeetCode, HackerRank)\\n- GitHub repos or open-source projects\\n- YouTube Tutorials\\n- Blogs, articles, or documentation etc-\\n\\nEnsure resources are **practical**, well-reviewed, REAL and up-to-date.\\n\\nRespond ONLY in valid JSON:\\n\\n{{\\n  \"technical_skill_resources\": {{\\n    \"Skill 1\": [\"Resource A\", \"Resource B\"],\\n    ...\\n  }},\\n  \"soft_skill_resources\": {{\\n    \"Skill 1\": [\"Resource A\", \"Resource B\"],\\n    ...\\n  }},\\n  \"transferable_skill_resources\": {{\\n    \"Skill 1\": [\"Resource A\", \"Resource B\"]\\n  }}\\n}}\\n\\nNo explanations. No markdown. No extra text. Just the JSON object. DO NOT make up fake links. Use only real, high-quality resources.\\n\\n---\\n\\nTechnical Skills Gap: {\\', \\'.join(tech_skills)}\\nSoft Skills Gap: {\\', \\'.join(soft_skills)}\\nTransferable Skills: {\\', \\'.join(transferable_skills)}\\n\"\"\"\\n\\n    try:\\n        response = client.chat.completions.create(\\n            model=\"gpt-4o-mini\",\\n            messages=[\\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant for job upskilling.\"},\\n                {\"role\": \"user\", \"content\": prompt}\\n            ],\\n            temperature=0.2\\n        )\\n        raw_output = response.choices[0].message.content.strip()\\n        return extract_json_from_response(raw_output)\\n    except Exception as e:\\n        print(\"API Error:\", e)\\n        return {}\\n\\nresults = []\\n\\nfor idx, row in df.iterrows():\\n    name = row.get(\"name\", f\"Candidate_{idx}\")\\n    print(f\"[{name}] ‚Üí Generating action plan...\")\\n\\n    tech = [s.strip() for s in str(row.get(\"technical_skill_gap\", \"\")).split(\",\") if s.strip()]\\n    soft = [s.strip() for s in str(row.get(\"soft_skill_gap\", \"\")).split(\",\") if s.strip()]\\n    trans = [s.strip() for s in str(row.get(\"transferable_skills\", \"\")).split(\",\") if s.strip()]\\n\\n    if not tech and not soft and not trans:\\n        print(\"   ‚Üí No skill gaps found. Skipping.\")\\n        continue\\n\\n    plan = generate_action_plan(tech, soft, trans)\\n\\n    results.append({\\n        \"name\": name,\\n        \"target_role\": row.get(\"target_role\", \"\"),\\n        \"technical_skill_gap\": tech,\\n        \"soft_skill_gap\": soft,\\n        \"transferable_skills\": trans,\\n        \"action_plan\": plan\\n    })\\n\\n    time.sleep(1)\\n\\nwith open(\"test_action_plan_output.json\", \"w\") as f:\\n    json.dump(results, f, indent=2)\\n\\nprint(f\"\\\\n Test complete! Results saved to \\'test_action_plan_output.json\\'\")'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'page_1', 'lines': '24-35', 'sections': ['Usage Instructions'], 'tags': ['streamlit', 'title', 'text input', 'button', 'session state'], 'rationale': 'This code chunk provides instructions on how to use the application by prompting the user for their name and email before proceeding to the next step.'}, page_content='def page_1():\\n    st.title(\"Welcome to StepUpYourCareer.AI\")\\n    st.markdown(\"##### Let\\'s get started with a few details.\")\\n\\n    name = st.text_input(\"Your Full Name\")\\n    email = st.text_input(\"Your Email Address\")\\n\\n    if name and email:\\n        if st.button(\"‚û°Ô∏è Proceed to Resume Analysis\"):\\n            st.session_state.name = name\\n            st.session_state.email = email\\n            st.session_state.page = 2'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'load_examples', 'lines': '37-44', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='def load_examples():\\n            with open(\"/mount/src/stepupyourcareer.ai/StepUpAI/skill_gap_analysis.json\", \"r\") as f:\\n                examples = json.load(f)\\n            example_texts = [\\n                f\"Resume: {ex[\\'resume_summary\\']} | Role: {ex[\\'target_role\\']}\" for ex in examples\\n            ]\\n            embeddings = [get_embedding(text) for text in example_texts]\\n            return examples, embeddings'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'load_role_skills', 'lines': '48-57', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='def load_role_skills():\\n    with open(\"/mount/src/stepupyourcareer.ai/StepUpAI/role_skills.json\", \"r\") as f:\\n        role_skills_list = json.load(f)\\n        return {\\n            entry[\"role\"]: {\\n                \"technical_skills\": entry.get(\"technical_skills\", []),\\n                \"soft_skills\": entry.get(\"soft_skills\", [])\\n                }\\n            for entry in role_skills_list if \"role\" in entry\\n            }'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'get_embedding', 'lines': '60-62', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='def get_embedding(text, model=\"text-embedding-ada-002\"):\\n    response = client.embeddings.create(input=[text], model=model)\\n    return response.data[0].embedding'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'extract_text_from_pdf', 'lines': '65-67', 'sections': ['Usage Instructions', 'Tech Stack'], 'tags': ['extract', 'text', 'PDF', 'reader', 'pages', 'method', 'class'], 'rationale': 'The function defines a method to extract text from a PDF file, making it relevant for the Usage Instructions section. It also mentions the PdfReader class, which is part of the Tech Stack.'}, page_content='def extract_text_from_pdf(uploaded_file):\\n    reader = PdfReader(uploaded_file)\\n    return \"\\\\n\".join([page.extract_text() or \"\" for page in reader.pages])'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'anonymize', 'lines': '70-79', 'sections': ['Usage Instructions', 'API Documentation'], 'tags': ['anonymize', 'text', 'client', 'chat', 'completions', 'model', 'API', 'AI', 'function'], 'rationale': 'This code snippet provides a function to anonymize text using an AI model, making it suitable for both Usage Instructions and API Documentation sections.'}, page_content='def anonymize(text):\\n    response = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant that removes personal identifiers from resumes.\"},\\n        {\"role\": \"user\", \"content\": f\"Anonymize this resume:\\\\n\\\\n{text}\"}\\n        ],\\n        temperature=0\\n        )\\n    return response.choices[0].message.content.strip()'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'retrieve_examples', 'lines': '82-86', 'sections': ['Objective & Scope', 'Tech Stack'], 'tags': ['retrieve', 'examples', 'query', 'embeddings', 'cosine similarity', 'function', 'top-k', 'sklearn', 'embedding'], 'rationale': 'This code snippet defines a function to retrieve examples based on a query and embeddings, aligning with the objective of the project. It also showcases the use of embeddings and cosine similarity, which are part of the tech stack.'}, page_content='def retrieve_examples(query, embeddings, examples, k=3):\\n    query_emb = get_embedding(query)\\n    sims = sk_cosine([query_emb], embeddings)[0]\\n    top_k = sims.argsort()[-k:][::-1]\\n    return [examples[i] for i in top_k]'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'generate_skill_gap', 'lines': '89-129', 'sections': ['Objective & Scope', 'Usage Instructions', 'API Documentation'], 'tags': ['skill gap', 'resume', 'target role', 'technical skills', 'soft skills', 'transferable skills', 'JSON', 'GPT-4', 'chat completions'], 'rationale': 'The code defines a function to generate skill gap analysis based on a given resume, target role, examples, and fallback skills. It outlines the objective, provides usage instructions for the function, and specifies the expected API response format.'}, page_content='def generate_skill_gap(resume_text, target_role, retrieved_examples, fallback_skills):\\n    examples_prompt = \"\\\\n\\\\n\".join([\\n    f\"Example for role {ex[\\'target_role\\']}:\\\\nResume: {ex[\\'resume_summary\\']}\\\\nSkill Gaps: tech={ex[\\'technical_skill_gap\\']}, soft={ex[\\'soft_skill_gap\\']}, transferable={ex[\\'transferable_skills\\']}\"\\n    for ex in retrieved_examples\\n        ])\\n    expected_tech = fallback_skills.get(\"technical_skills\", [])\\n    expected_soft = fallback_skills.get(\"soft_skills\", [])\\n\\n    prompt = f\"\"\"\\n        You are a highly experienced career advisor. Based on examples and required skills, identify skill gaps.\\n\\n        ## EXAMPLES\\n        {examples_prompt}\\n\\n        ## TASK:\\n\\n        Analyze the new resume below and return only JSON:\\n        {{\\n        \"technical_skill_gaps\": [list of missing technical skills],\\n        \"soft_skill_gaps\": [list of missing soft skills],\\n        \"transferable_skills\": [skills from the resume that help bridge gaps]\\n        }}\\n\\n        No explanation, no markdown, just clean JSON.\\n\\n        Target Role: {target_role}\\n        Required Technical Skills: {\\', \\'.join(expected_tech)}\\n        Required Soft Skills: {\\', \\'.join(expected_soft)}\\n        Resume:\\n        {resume_text}\\n        \"\"\"\\n\\n    response = client.chat.completions.create(\\n        model=\"gpt-4o-mini\",\\n        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant for skill gap analysis.\"},\\n        {\"role\": \"user\", \"content\": prompt}],\\n        temperature=0.0\\n        )\\n    raw = response.choices[0].message.content.strip()\\n    raw = re.sub(r\"```json|```\", \"\", raw)\\n    return json.loads(raw)'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'get_skill_priorities_from_gpt', 'lines': '131-160', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='def get_skill_priorities_from_gpt(skills, role):\\n    prompt = f\"\"\"\\n    You are a career advisor. For the target role \\'{role}\\', prioritize the following skills based on the 80/20 (Pareto) principle.\\n\\n    Skills:\\n    {\\', \\'.join(skills)}\\n\\n    Return JSON mapping each skill to an importance score from 1 to 100 (higher means more important). Output should look like:\\n    {{\\n      \"Skill1\": 95,\\n      \"Skill2\": 90,\\n      ...\\n    }}\\n\\n    No explanation. No markdown. Only JSON.\\n    \"\"\"\\n    response = client.chat.completions.create(\\n        model=\"gpt-4o-mini\",\\n        messages=[\\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant that ranks skills by importance.\"},\\n            {\"role\": \"user\", \"content\": prompt}\\n        ],\\n        temperature=0.2\\n    )\\n    raw = response.choices[0].message.content.strip()\\n    raw = re.sub(r\"```json|```\", \"\", raw)\\n    try:\\n        return json.loads(raw)\\n    except json.JSONDecodeError:\\n        return {}'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'extract_json_from_response', 'lines': '164-171', 'sections': ['Objective & Scope', 'Tech Stack'], 'tags': ['extract', 'JSON', 'response', 're', 'json.loads', 'JSONDecodeError'], 'rationale': \"This code snippet defines a function to extract JSON data from a response, aligning with the objective of data extraction and manipulation. It also utilizes the Python 'json' library, indicating the tech stack being used.\"}, page_content='def extract_json_from_response(raw):\\n    match = re.search(r\"\\\\{[\\\\s\\\\S]*\\\\}\", raw)\\n    if match:\\n        try:\\n            return json.loads(match.group())\\n        except json.JSONDecodeError:\\n            return {}\\n    return {}'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'load_skill_resources', 'lines': '173-175', 'sections': ['Installation & Setup', 'Usage Instructions'], 'tags': ['load', 'skill', 'resources', 'json', 'file', 'open', 'read'], 'rationale': 'This code snippet is relevant for both Installation & Setup as it shows how to load skill resources, and for Usage Instructions as it demonstrates how to use the loaded resources.'}, page_content='def load_skill_resources():\\n    with open(\"/mount/src/stepupyourcareer.ai/StepUpAI/skill_resource_mapping.json\", \"r\") as f:\\n        return json.load(f)'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'split_skills_by_rag_presence', 'lines': '178-186', 'sections': ['Others'], 'tags': [], 'rationale': 'Failed to parse response'}, page_content='def split_skills_by_rag_presence(skills, rag_skill_keys):\\n    present = []\\n    missing = []\\n    for skill in skills:\\n        if skill.strip().upper() in rag_skill_keys:\\n            present.append(skill)\\n        else:\\n            missing.append(skill)\\n    return present, missing'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\app.py', 'file_ext': 'code', 'type': 'functiondef', 'name': 'generate_hybrid_action_plan', 'lines': '188-268', 'sections': ['Usage Instructions', 'Others'], 'tags': ['GPT', 'resources', 'skills', 'RAG', 'JSON', 'exception handling', 'client', 'completions', 'prompt'], 'rationale': 'This code chunk provides usage instructions on how to generate a hybrid action plan for skills, including constructing RAG results and preparing a GPT prompt for uncovered skills. It also handles exceptions during the GPT generation process.'}, page_content='def generate_hybrid_action_plan(tech, soft, trans, skill_resources):\\n    # Split all three skill types\\n    tech_in, tech_out = split_skills_by_rag_presence(tech, skill_resources.keys())\\n    soft_in, soft_out = split_skills_by_rag_presence(soft, skill_resources.keys())\\n    trans_in, trans_out = split_skills_by_rag_presence(trans, skill_resources.keys())\\n\\n    #  Construct RAG results\\n    def extract_rag(skills):\\n        result = {}\\n        for s in skills:\\n            key = s.strip().upper()\\n            if key in skill_resources:\\n                    result[s] = skill_resources[key]\\n        return result\\n\\n    plan = {\\n            \"message\": \"Here\\'s a complete roadmap with relevant resources\",\\n            \"technical_skill_resources\": extract_rag(tech_in),\\n            \"soft_skill_resources\": extract_rag(soft_in),\\n            \"transferable_skill_resources\": extract_rag(trans_in)\\n    }\\n\\n    # Prepare GPT prompt only for uncovered skills\\n    if tech_out or soft_out or trans_out:\\n        prompt = f\"\"\"\\n        You are a career coach. Only generate resources for the following skills not found in our internal library.\\n\\n        Provide for each:\\n        - One **top-rated course** with real working URL.\\n        - One **real book** just name & author and AMAZON links for buying that book.\\n        - For soft/transferable skills, one article or video (with URL).\\n\\n        Format your response in JSON like this:\\n        {{\\n        \"technical_skill_resources\": {{\\n            \"Skill\": [{{\"title\": \"...\", \"url\": \"...\" }}, {{\"title\": \"Book by Author\"}}]\\n        }},\\n        \"soft_skill_resources\": {{\\n            \"Skill\": [{{\"title\": \"...\", \"url\": \"...\" }}]\\n        }},\\n        \"transferable_skill_resources\": {{\\n            \"Skill\": [{{\"title\": \"...\", \"url\": \"...\" }}]\\n        }}\\n        }}\\n\\n        Only cover these:\\n        - TECHNICAL: {\\', \\'.join(tech_out)}\\n        - SOFT: {\\', \\'.join(soft_out)}\\n        - TRANSFERABLE: {\\', \\'.join(trans_out)}\\n\\n        You will be penalized if you confabulate or hallucinate by creating fake resources. It should be 100% authenthic.\\n        Double check every link/resource you give. If you don\\'t get any links leave that section blank.\\n        No explanations. No markdown. Only JSON.\\n        \"\"\"\\n        try:\\n            response = client.chat.completions.create(\\n            # Change to GPT 4 to get accurate links to resources\\n            model=\"gpt-4o-mini\",\\n            messages=[\\n                    {\"role\": \"system\", \"content\": \"You are a helpful assistant for learning.\"},\\n                    {\"role\": \"user\", \"content\": prompt}\\n                    ],\\n                    temperature=0.2\\n                    )\\n            raw = response.choices[0].message.content.strip()\\n            raw = re.sub(r\"```json|```\", \"\", raw)\\n            gpt_part = extract_json_from_response(raw)\\n\\n            if not isinstance(gpt_part, dict):\\n                gpt_part = {}\\n\\n            # Merge GPT results into RAG base\\n            for k in [\"technical_skill_resources\", \"soft_skill_resources\", \"transferable_skill_resources\"]:\\n                if k in gpt_part and isinstance(plan.get(k), dict):\\n                    plan[k].update(gpt_part[k])\\n\\n\\n        except Exception as e:\\n                st.error(f\"Error generating GPT fallback plan: {e}\")\\n\\n        return plan'),\n",
       " Document(metadata={'source': 'tmp_repo\\\\StepUpAI\\\\requirements.txt', 'file_ext': 'code', 'type': '.txt', 'name': 'requirements.txt', 'lines': '1-10', 'sections': ['Tech Stack'], 'tags': ['streamlit', 'openai', 'PyPDF2', 'pandas', 'scikit-learn', 'tqdm', 'numpy', 'joblib'], 'rationale': 'This chunk lists the required libraries for the project, indicating the technology stack being used.'}, page_content='streamlit\\nopenai>=1.0.0\\nPyPDF2\\npandas\\nscikit-learn\\ntqdm\\nnumpy\\npandas\\njoblib\\n')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43097103",
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (3361902121.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mif \"Usage Instructions\" in doc.metadata.get(\"sections\", [])\u001b[39m\n                                                               ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "selected_chunks = [\n",
    "    doc for doc in chunks\n",
    "    if \"Usage Instructions\" in doc.metadata.get(\"sections\", [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbcad65",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Result 1:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_0\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 0\n",
      "üß† Content preview:\n",
      " <a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Job_Description_JD_Manupulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> ...\n",
      "\n",
      "\n",
      "üîπ Result 2:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_0\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 0\n",
      "üß† Content preview:\n",
      " <a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> ...\n",
      "\n",
      "\n",
      "üîπ Result 3:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_23\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 23\n",
      "üß† Content preview:\n",
      " ### Action Plan Generation (Testing for 3 Candidates) ...\n",
      "\n",
      "\n",
      "üîπ Result 4:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_16\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 16\n",
      "üß† Content preview:\n",
      " ### File containing all common skills required for a particular role ...\n",
      "\n",
      "\n",
      "üîπ Result 5:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_12\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 12\n",
      "üß† Content preview:\n",
      " ### Printing 120 job descriptions for each role (Total 600) ...\n",
      "\n",
      "\n",
      "üîπ Result 6:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_14\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 14\n",
      "üß† Content preview:\n",
      " ### Extracting common required technical and soft skills required for each role. ...\n",
      "\n",
      "\n",
      "üîπ Result 7:\n",
      "üìÑ File: tmp_repo\\README.md\n",
      "üìå Type: .md\n",
      "üî¢ Lines: 1-32\n",
      "üìõ Name: README.md\n",
      "üß† Content preview:\n",
      " # StepUpYourCareer.ai: Elevate Your Future\n",
      "\n",
      "An AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\n",
      "\n",
      "### Link to the website: https://stepupyourcaree ...\n",
      "\n",
      "\n",
      "üîπ Result 8:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_20\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 20\n",
      "üß† Content preview:\n",
      " ### Skill Gap Analysis Functionality - allows user to upload their resume ...\n",
      "\n",
      "\n",
      "üîπ Result 9:\n",
      "üìÑ File: tmp_repo\\README.md\n",
      "üìå Type: .md\n",
      "üî¢ Lines: 1-29\n",
      "üìõ Name: README.md\n",
      "üß† Content preview:\n",
      " # StepUpYourCareer.ai: Elevate Your Future\n",
      "\n",
      "An AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\n",
      "\n",
      "### Link to the website: https://stepupyourcaree ...\n",
      "\n",
      "\n",
      "üîπ Result 10:\n",
      "üìÑ File: tmp_repo\\README.md\n",
      "üìå Type: readme\n",
      "üî¢ Lines: 1-29\n",
      "üìõ Name: README.md\n",
      "üß† Content preview:\n",
      " # StepUpYourCareer.ai: Elevate Your Future\n",
      "\n",
      "An AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\n",
      "\n",
      "### Link to the website: https://stepupyourcaree ...\n",
      "\n",
      "\n",
      "üîπ Result 11:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_0\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 0\n",
      "üß† Content preview:\n",
      " <a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUpYourCareer.AI/blob/Clustering/ClusteringMentorModelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> ...\n",
      "\n",
      "\n",
      "üîπ Result 12:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_4\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 4\n",
      "üß† Content preview:\n",
      " ## Prompt to generate Mentors with skills of experties ...\n",
      "\n",
      "\n",
      "üîπ Result 13:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " upyourcareer.ai/StepUpAI/mentors_final_data.json\")\n",
      "\n",
      "def page_2():\n",
      "    st.title(\"üìÑ Resume Analyzer + Mentor Recommender\")\n",
      "    st.markdown(f\"**üë§ Name:** {st.session_state.name}  |  **üìß Email:** {st.session_state.email}\")\n",
      "\n",
      "    st.markdown(\"Please ensure your resume reflects your true skills and experie ...\n",
      "\n",
      "\n",
      "üîπ Result 14:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      "  = m.get(\"bio\", \"N/A\")\n",
      "                    linkedin = m.get(\"linkedin_id\", \"\")\n",
      "                    html += f\"\"\"\n",
      "                    <tr>\n",
      "                        <td>{name}</td>\n",
      "                        <td>{skills}</td>\n",
      "                        <td>{bio}</td>\n",
      "                        <td><a href=\"https ...\n",
      "\n",
      "\n",
      "üîπ Result 15:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_19\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 19\n",
      "üß† Content preview:\n",
      " # Load Files\n",
      "with open(\"sim_resume.json\", \"r\") as f:\n",
      "    resumes = [json.loads(line) for line in f]\n",
      "\n",
      "with open(\"role_skills.json\", \"r\") as f:\n",
      "    raw_roles = json.load(f)\n",
      "role_skills = {r[\"role\"]: r for r in raw_roles}\n",
      "\n",
      "# Helper Functions\n",
      "def summarize_resume(resume):\n",
      "    \"\"\"Summarize fields from a  ...\n",
      "\n",
      "\n",
      "üîπ Result 16:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 24-35\n",
      "üìõ Name: page_1\n",
      "üß† Content preview:\n",
      " def page_1():\n",
      "    st.title(\"Welcome to StepUpYourCareer.AI\")\n",
      "    st.markdown(\"##### Let's get started with a few details.\")\n",
      "\n",
      "    name = st.text_input(\"Your Full Name\")\n",
      "    email = st.text_input(\"Your Email Address\")\n",
      "\n",
      "    if name and email:\n",
      "        if st.button(\"‚û°Ô∏è Proceed to Resume Analysis\"):\n",
      "      ...\n",
      "\n",
      "\n",
      "üîπ Result 17:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 188-268\n",
      "üìõ Name: generate_hybrid_action_plan\n",
      "üß† Content preview:\n",
      " def generate_hybrid_action_plan(tech, soft, trans, skill_resources):\n",
      "    # Split all three skill types\n",
      "    tech_in, tech_out = split_skills_by_rag_presence(tech, skill_resources.keys())\n",
      "    soft_in, soft_out = split_skills_by_rag_presence(soft, skill_resources.keys())\n",
      "    trans_in, trans_out = split ...\n",
      "\n",
      "\n",
      "üîπ Result 18:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " \": prompt}],\n",
      "        temperature=0.0\n",
      "        )\n",
      "    raw = response.choices[0].message.content.strip()\n",
      "    raw = re.sub(r\"```json|```\", \"\", raw)\n",
      "    return json.loads(raw)\n",
      "\n",
      "def get_skill_priorities_from_gpt(skills, role):\n",
      "    prompt = f\"\"\"\n",
      "    You are a career advisor. For the target role '{role}', pr ...\n",
      "\n",
      "\n",
      "üîπ Result 19:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " 3 distinct skill names\n",
      "        top_skills = []\n",
      "        for s in ranked_skills:\n",
      "            if s not in top_skills:\n",
      "                top_skills.append(s)\n",
      "            if len(top_skills) == 3:\n",
      "                break\n",
      "\n",
      "        # Show top 3\n",
      "        for i, skill in enumerate(top_skills, 1):\n",
      "            st.ma ...\n",
      "\n",
      "\n",
      "üîπ Result 20:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_14\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 14\n",
      "üß† Content preview:\n",
      " ### Using TSNE to see if the clustering algorithm is grouping based on skills or based on roles ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query for architecture-related info\n",
    "arch_query = \"System Architecture\"\n",
    "arch_docs = db.similarity_search(arch_query, k=20)\n",
    "\n",
    "# Preview content and metadata for each chunk\n",
    "for i, doc in enumerate(arch_docs, start=1):\n",
    "    print(f\"\\nüîπ Result {i}:\")\n",
    "    print(\"üìÑ File:\", doc.metadata.get(\"source\"))\n",
    "    print(\"üìå Type:\", doc.metadata.get(\"type\"))\n",
    "    print(\"üî¢ Lines:\", doc.metadata.get(\"lines\"))\n",
    "    print(\"üìõ Name:\", doc.metadata.get(\"name\"))\n",
    "    print(\"üß† Content preview:\\n\", doc.page_content[:300], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8f08796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='6c647709-aed9-4f66-b4a6-c5830eba1e38', metadata={'source': 'tmp_repo\\\\Job_Description_JD_Manupulation.ipynb', 'type': 'markdown_cell', 'name': 'Job_Description_JD_Manupulation.ipynb - cell 0', 'lines': 'cell_0'}, page_content='<a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Job_Description_JD_Manupulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f2a7f5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Result 1:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_23\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 23\n",
      "üß† Content preview:\n",
      " ### Action Plan Generation (Testing for 3 Candidates) ...\n",
      "\n",
      "\n",
      "üîπ Result 2:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_0\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 0\n",
      "üß† Content preview:\n",
      " <a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> ...\n",
      "\n",
      "\n",
      "üîπ Result 3:\n",
      "üìÑ File: tmp_repo\\README.md\n",
      "üìå Type: .md\n",
      "üî¢ Lines: 1-32\n",
      "üìõ Name: README.md\n",
      "üß† Content preview:\n",
      " # StepUpYourCareer.ai: Elevate Your Future\n",
      "\n",
      "An AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\n",
      "\n",
      "### Link to the website: https://stepupyourcaree ...\n",
      "\n",
      "\n",
      "üîπ Result 4:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_0\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 0\n",
      "üß† Content preview:\n",
      " <a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Job_Description_JD_Manupulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> ...\n",
      "\n",
      "\n",
      "üîπ Result 5:\n",
      "üìÑ File: tmp_repo\\README.md\n",
      "üìå Type: .md\n",
      "üî¢ Lines: 1-29\n",
      "üìõ Name: README.md\n",
      "üß† Content preview:\n",
      " # StepUpYourCareer.ai: Elevate Your Future\n",
      "\n",
      "An AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\n",
      "\n",
      "### Link to the website: https://stepupyourcaree ...\n",
      "\n",
      "\n",
      "üîπ Result 6:\n",
      "üìÑ File: tmp_repo\\README.md\n",
      "üìå Type: readme\n",
      "üî¢ Lines: 1-29\n",
      "üìõ Name: README.md\n",
      "üß† Content preview:\n",
      " # StepUpYourCareer.ai: Elevate Your Future\n",
      "\n",
      "An AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\n",
      "\n",
      "### Link to the website: https://stepupyourcaree ...\n",
      "\n",
      "\n",
      "üîπ Result 7:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_0\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 0\n",
      "üß† Content preview:\n",
      " <a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUpYourCareer.AI/blob/Clustering/ClusteringMentorModelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> ...\n",
      "\n",
      "\n",
      "üîπ Result 8:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_16\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 16\n",
      "üß† Content preview:\n",
      " ### File containing all common skills required for a particular role ...\n",
      "\n",
      "\n",
      "üîπ Result 9:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_12\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 12\n",
      "üß† Content preview:\n",
      " ### Printing 120 job descriptions for each role (Total 600) ...\n",
      "\n",
      "\n",
      "üîπ Result 10:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 188-268\n",
      "üìõ Name: generate_hybrid_action_plan\n",
      "üß† Content preview:\n",
      " def generate_hybrid_action_plan(tech, soft, trans, skill_resources):\n",
      "    # Split all three skill types\n",
      "    tech_in, tech_out = split_skills_by_rag_presence(tech, skill_resources.keys())\n",
      "    soft_in, soft_out = split_skills_by_rag_presence(soft, skill_resources.keys())\n",
      "    trans_in, trans_out = split ...\n",
      "\n",
      "\n",
      "üîπ Result 11:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_14\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 14\n",
      "üß† Content preview:\n",
      " ### Extracting common required technical and soft skills required for each role. ...\n",
      "\n",
      "\n",
      "üîπ Result 12:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_20\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 20\n",
      "üß† Content preview:\n",
      " ### Skill Gap Analysis Functionality - allows user to upload their resume ...\n",
      "\n",
      "\n",
      "üîπ Result 13:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_4\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 4\n",
      "üß† Content preview:\n",
      " ## Prompt to generate Mentors with skills of experties ...\n",
      "\n",
      "\n",
      "üîπ Result 14:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " \": prompt}],\n",
      "        temperature=0.0\n",
      "        )\n",
      "    raw = response.choices[0].message.content.strip()\n",
      "    raw = re.sub(r\"```json|```\", \"\", raw)\n",
      "    return json.loads(raw)\n",
      "\n",
      "def get_skill_priorities_from_gpt(skills, role):\n",
      "    prompt = f\"\"\"\n",
      "    You are a career advisor. For the target role '{role}', pr ...\n",
      "\n",
      "\n",
      "üîπ Result 15:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " 3 distinct skill names\n",
      "        top_skills = []\n",
      "        for s in ranked_skills:\n",
      "            if s not in top_skills:\n",
      "                top_skills.append(s)\n",
      "            if len(top_skills) == 3:\n",
      "                break\n",
      "\n",
      "        # Show top 3\n",
      "        for i, skill in enumerate(top_skills, 1):\n",
      "            st.ma ...\n",
      "\n",
      "\n",
      "üîπ Result 16:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      "  = m.get(\"bio\", \"N/A\")\n",
      "                    linkedin = m.get(\"linkedin_id\", \"\")\n",
      "                    html += f\"\"\"\n",
      "                    <tr>\n",
      "                        <td>{name}</td>\n",
      "                        <td>{skills}</td>\n",
      "                        <td>{bio}</td>\n",
      "                        <td><a href=\"https ...\n",
      "\n",
      "\n",
      "üîπ Result 17:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      "  background-color: #1e1e1e; box-shadow: 0 4px 12px rgba(0,0,0,0.25); color: white;'>\"\n",
      "                    item_html += f\"<h5 style='font-size: 1.2rem; margin-bottom: 10px;'>{skill}</h5><ul style='margin-top: 10px;'>\"\n",
      "                    for item in items:\n",
      "                        if isinstance(item,  ...\n",
      "\n",
      "\n",
      "üîπ Result 18:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " _html.format(\n",
      "            \"\".join([f\"<li>{s}</li>\" for s in gaps[\"technical_skill_gaps\"]]),\n",
      "            \"\".join([f\"<li>{s}</li>\" for s in gaps[\"soft_skill_gaps\"]]),\n",
      "            \"\".join([f\"<li>{s}</li>\" for s in gaps[\"transferable_skills\"]])\n",
      "        ), unsafe_allow_html=True)\n",
      "\n",
      "        st.subheader(\"üìò ...\n",
      "\n",
      "\n",
      "üîπ Result 19:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_14\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 14\n",
      "üß† Content preview:\n",
      " ### Using TSNE to see if the clustering algorithm is grouping based on skills or based on roles ...\n",
      "\n",
      "\n",
      "üîπ Result 20:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " upyourcareer.ai/StepUpAI/mentors_final_data.json\")\n",
      "\n",
      "def page_2():\n",
      "    st.title(\"üìÑ Resume Analyzer + Mentor Recommender\")\n",
      "    st.markdown(f\"**üë§ Name:** {st.session_state.name}  |  **üìß Email:** {st.session_state.email}\")\n",
      "\n",
      "    st.markdown(\"Please ensure your resume reflects your true skills and experie ...\n",
      "\n",
      "\n",
      "üîπ Result 21:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      "  {\"role\": \"user\", \"content\": prompt}\n",
      "                    ],\n",
      "                    temperature=0.2\n",
      "                    )\n",
      "            raw = response.choices[0].message.content.strip()\n",
      "            raw = re.sub(r\"```json|```\", \"\", raw)\n",
      "            gpt_part = extract_json_from_response(raw)\n",
      "\n",
      "            if ...\n",
      "\n",
      "\n",
      "üîπ Result 22:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " soft_skill_resources\", {}))\n",
      "        render_resources_flex(\"üîÑ Transferable Skills\", plan.get(\"transferable_skill_resources\", {}))\n",
      "\n",
      "        st.subheader(\"üë• Recommended Mentors\")\n",
      "        try:\n",
      "            skill_list = [s.strip() for s in tech if s.strip()]\n",
      "            mlb_vector = vectorizer.transform([ ...\n",
      "\n",
      "\n",
      "üîπ Result 23:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " |```\", \"\", raw)\n",
      "    try:\n",
      "        return json.loads(raw)\n",
      "    except json.JSONDecodeError:\n",
      "        return {}\n",
      "\n",
      "\n",
      "# Action Plan Generator\n",
      "def extract_json_from_response(raw):\n",
      "    match = re.search(r\"\\{[\\s\\S]*\\}\", raw)\n",
      "    if match:\n",
      "        try:\n",
      "            return json.loads(match.group())\n",
      "        except  ...\n",
      "\n",
      "\n",
      "üîπ Result 24:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_19\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 19\n",
      "üß† Content preview:\n",
      " # Load Files\n",
      "with open(\"sim_resume.json\", \"r\") as f:\n",
      "    resumes = [json.loads(line) for line in f]\n",
      "\n",
      "with open(\"role_skills.json\", \"r\") as f:\n",
      "    raw_roles = json.load(f)\n",
      "role_skills = {r[\"role\"]: r for r in raw_roles}\n",
      "\n",
      "# Helper Functions\n",
      "def summarize_resume(resume):\n",
      "    \"\"\"Summarize fields from a  ...\n",
      "\n",
      "\n",
      "üîπ Result 25:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_16\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 16\n",
      "üß† Content preview:\n",
      " ### Clustering happeining on skills cause within each role there are still overlapping clusters, means skills are common within each roles ...\n",
      "\n",
      "\n",
      "üîπ Result 26:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      "  Role: {target_role}\"\n",
      "        retrieved = retrieve_examples(query, example_embeddings, examples)\n",
      "\n",
      "        gaps = generate_skill_gap(anonymized_resume, target_role, retrieved, fallback_skills)\n",
      "\n",
      "        all_skills = list(set(gaps[\"technical_skill_gaps\"] + gaps[\"soft_skill_gaps\"] + gaps[\"transferable_s ...\n",
      "\n",
      "\n",
      "üîπ Result 27:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " import streamlit as st\n",
      "import json\n",
      "import pandas as pd\n",
      "import re\n",
      "import time\n",
      "from PyPDF2 import PdfReader\n",
      "from openai import OpenAI\n",
      "from sklearn.metrics.pairwise import cosine_similarity as sk_cosine\n",
      "import joblib\n",
      "import numpy as np\n",
      "\n",
      "# === Set up client ===\n",
      "st.set_page_config(page_title=\"StepUpYourC ...\n",
      "\n",
      "\n",
      "üîπ Result 28:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      "  skill_resources.keys())\n",
      "    trans_in, trans_out = split_skills_by_rag_presence(trans, skill_resources.keys())\n",
      "\n",
      "    #  Construct RAG results\n",
      "    def extract_rag(skills):\n",
      "        result = {}\n",
      "        for s in skills:\n",
      "            key = s.strip().upper()\n",
      "            if key in skill_resources:\n",
      "           ...\n",
      "\n",
      "\n",
      "üîπ Result 29:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 24-35\n",
      "üìõ Name: page_1\n",
      "üß† Content preview:\n",
      " def page_1():\n",
      "    st.title(\"Welcome to StepUpYourCareer.AI\")\n",
      "    st.markdown(\"##### Let's get started with a few details.\")\n",
      "\n",
      "    name = st.text_input(\"Your Full Name\")\n",
      "    email = st.text_input(\"Your Email Address\")\n",
      "\n",
      "    if name and email:\n",
      "        if st.button(\"‚û°Ô∏è Proceed to Resume Analysis\"):\n",
      "      ...\n",
      "\n",
      "\n",
      "üîπ Result 30:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_5\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 5\n",
      "üß† Content preview:\n",
      " roles = [\n",
      "    \"Artificial Intelligence\",\n",
      "    \"Business Analyst\",\n",
      "    \"Business Intelligence Analyst\",\n",
      "    \"Data Analyst\",\n",
      "    \"Machine Learning\"\n",
      "] ...\n",
      "\n",
      "\n",
      "üîπ Result 31:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      "  {{\n",
      "            \"Skill\": [{{\"title\": \"...\", \"url\": \"...\" }}, {{\"title\": \"Book by Author\"}}]\n",
      "        }},\n",
      "        \"soft_skill_resources\": {{\n",
      "            \"Skill\": [{{\"title\": \"...\", \"url\": \"...\" }}]\n",
      "        }},\n",
      "        \"transferable_skill_resources\": {{\n",
      "            \"Skill\": [{{\"title\": \"...\", \"url\": \". ...\n",
      "\n",
      "\n",
      "üîπ Result 32:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_15\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 15\n",
      "üß† Content preview:\n",
      " jobs_df = pd.read_csv(\"req_job_desc.csv\")\n",
      "\n",
      "# Group by target role\n",
      "grouped_roles = jobs_df.groupby(\"Query\")\n",
      "\n",
      "def extract_skills_from_descriptions(role, descriptions):\n",
      "    combined_text = \"\\n\\n---\\n\\n\".join(descriptions)\n",
      "\n",
      "    prompt = f\"\"\"\n",
      "      You are a highly skilled AI career advisor. You are give ...\n",
      "\n",
      "\n",
      "üîπ Result 33:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " 4px 12px rgba(0,0,0,0.15); background-color: #1e1e1e;'>\n",
      "                <h4 style='color:white;'>Technical Skill Gaps</h4>\n",
      "                <ul style='color:white;'>{}</ul>\n",
      "            </div>\n",
      "            <div style='flex: 1; padding: 20px; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15); ...\n",
      "\n",
      "\n",
      "üîπ Result 34:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_15\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 15\n",
      "üß† Content preview:\n",
      " tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
      "tsne_result = tsne.fit_transform(skills_df.values)\n",
      "\n",
      "plt.figure(figsize=(16, 6))  # one wide figure with 2 subplots\n",
      "\n",
      "# Subplot 1 ‚Äî using cluster labels\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=mentors_final_da ...\n",
      "\n",
      "\n",
      "üîπ Result 35:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_3\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 3\n",
      "üß† Content preview:\n",
      " jobs_desc = pd.read_csv(\"JobsDatasetProcessed.csv\")\n",
      "req_jobs_desc = jobs_desc.query(\"Query in ['Artificial Intelligence', 'Business Analyst', 'Business Intelligence Analyst', 'Data Analyst', 'Machine Learning']\")\n",
      "req_jobs_desc = req_jobs_desc[['Query', 'Description']] ...\n",
      "\n",
      "\n",
      "üîπ Result 36:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_21\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 21\n",
      "üß† Content preview:\n",
      " with open(\"skill_gap_analysis.json\", \"r\") as f:\n",
      "    examples = json.load(f)\n",
      "\n",
      "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
      "    response = client.embeddings.create(input=[text], model=model)\n",
      "    return response.data[0].embedding\n",
      "\n",
      "example_texts = [\n",
      "    f\"Resume: {ex['resume_summary']} | Rol ...\n",
      "\n",
      "\n",
      "üîπ Result 37:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " (\"/mount/src/stepupyourcareer.ai/StepUpAI/skill_gap_analysis.json\", \"r\") as f:\n",
      "                examples = json.load(f)\n",
      "            example_texts = [\n",
      "                f\"Resume: {ex['resume_summary']} | Role: {ex['target_role']}\" for ex in examples\n",
      "            ]\n",
      "            embeddings = [get_embedding( ...\n",
      "\n",
      "\n",
      "üîπ Result 38:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\requirements.txt\n",
      "üìå Type: .txt\n",
      "üî¢ Lines: 1-10\n",
      "üìõ Name: requirements.txt\n",
      "üß† Content preview:\n",
      " streamlit\n",
      "openai>=1.0.0\n",
      "PyPDF2\n",
      "pandas\n",
      "scikit-learn\n",
      "tqdm\n",
      "numpy\n",
      "pandas\n",
      "joblib\n",
      " ...\n",
      "\n",
      "\n",
      "üîπ Result 39:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_18\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 18\n",
      "üß† Content preview:\n",
      " ### Identifying skill gaps in the simulated resumes based on desired role ...\n",
      "\n",
      "\n",
      "üîπ Result 40:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_2\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 2\n",
      "üß† Content preview:\n",
      " from openai import OpenAI\n",
      "import json\n",
      "import time\n",
      "from google.colab import userdata\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import MultiLabelBinarizer\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.metrics import calinski_harabasz_score\n",
      "from ...\n",
      "\n",
      "\n",
      "üîπ Result 41:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_22\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 22\n",
      "üß† Content preview:\n",
      " from google.colab import files\n",
      "\n",
      "uploaded = files.upload()\n",
      "pdf_path = list(uploaded.keys())[0]\n",
      "\n",
      "target_role = input(\"Enter your target role (e.g., 'AI Engineer'): \").strip()\n",
      "\n",
      "output = analyze_uploaded_resume(pdf_path, target_role)\n",
      "\n",
      "print(json.dumps(output, indent=2)) ...\n",
      "\n",
      "\n",
      "üîπ Result 42:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_5\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 5\n",
      "üß† Content preview:\n",
      " def generate_mentor_prompt(role, tech_skills, n=10):\n",
      "    prompt = f\"\"\"\n",
      "You are an assistant helping to create a database of expert mentors.\n",
      "\n",
      "Generate {n} mentor profiles for the role: \"{role}\".\n",
      "\n",
      "Each mentor should have:\n",
      "- A realistic name\n",
      "- A short professional bio (1‚Äì2 sentences)\n",
      "- A list of 5‚Äì7 te ...\n",
      "\n",
      "\n",
      "üîπ Result 43:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_7\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 7\n",
      "üß† Content preview:\n",
      " def generate_student_resume(role: str):\n",
      "    prompt = f\"\"\"\n",
      "You are generating a **realistic and anonymized resume** for a computer science student or recent graduate (0‚Äì2 years of experience) applying for a role as a {role}.\n",
      "\n",
      "Return strictly valid JSON in the following format:\n",
      "{{\n",
      "  \"name\": \"Candidate ...\n",
      "\n",
      "\n",
      "üîπ Result 44:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 48-57\n",
      "üìõ Name: load_role_skills\n",
      "üß† Content preview:\n",
      " def load_role_skills():\n",
      "    with open(\"/mount/src/stepupyourcareer.ai/StepUpAI/role_skills.json\", \"r\") as f:\n",
      "        role_skills_list = json.load(f)\n",
      "        return {\n",
      "            entry[\"role\"]: {\n",
      "                \"technical_skills\": entry.get(\"technical_skills\", []),\n",
      "                \"soft_skills\": ent ...\n",
      "\n",
      "\n",
      "üîπ Result 45:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      "     return \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
      "\n",
      "# Resume anonymizer\n",
      "def anonymize(text):\n",
      "    response = client.chat.completions.create(\n",
      "    model=\"gpt-4o-mini\",\n",
      "    messages=[\n",
      "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that removes personal identif ...\n",
      "\n",
      "\n",
      "üîπ Result 46:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_24\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 24\n",
      "üß† Content preview:\n",
      " df = pd.read_csv(\"skill_gap_analysis.csv\").head(3)\n",
      "\n",
      "def extract_json_from_response(raw):\n",
      "    \"\"\"Safely extract JSON object from LLM response using regex.\"\"\"\n",
      "    match = re.search(r\"\\{[\\s\\S]*\\}\", raw)\n",
      "    if match:\n",
      "        try:\n",
      "            return json.loads(match.group())\n",
      "        except json.JSONDeco ...\n",
      "\n",
      "\n",
      "üîπ Result 47:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_4\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 4\n",
      "üß† Content preview:\n",
      " req_jobs_desc.loc[req_jobs_desc['Query'] == 'Artificial Intelligence', 'Query'] = 'AI Engineer'\n",
      "req_jobs_desc ...\n",
      "\n",
      "\n",
      "üîπ Result 48:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 173-175\n",
      "üìõ Name: load_skill_resources\n",
      "üß† Content preview:\n",
      " def load_skill_resources():\n",
      "    with open(\"/mount/src/stepupyourcareer.ai/StepUpAI/skill_resource_mapping.json\", \"r\") as f:\n",
      "        return json.load(f) ...\n",
      "\n",
      "\n",
      "üîπ Result 49:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_8\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 8\n",
      "üß† Content preview:\n",
      " mlb = MultiLabelBinarizer()\n",
      "skills_matrix = mlb.fit_transform(mentors_final_data['technical_skills'])\n",
      "joblib.dump(mlb, \"mlb.joblib\")\n",
      "skills_df = pd.DataFrame(skills_matrix, columns=mlb.classes_, index=mentors_final_data.index)\n",
      "skills_df.head(5) ...\n",
      "\n",
      "\n",
      "üîπ Result 50:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\sendemail-validate.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-78\n",
      "üìõ Name: sendemail-validate.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "\n",
      "# An example hook script to validate a patch (and/or patch series) before\n",
      "# sending it via email.\n",
      "#\n",
      "# The hook should exit with non-zero status after issuing an appropriate\n",
      "# message if it wants to prevent the email(s) from being sent.\n",
      "#\n",
      "# To enable this hook, rename this file to \"sendema ...\n",
      "\n",
      "\n",
      "üîπ Result 51:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " ex['soft_skill_gap']}, transferable={ex['transferable_skills']}\"\n",
      "    for ex in retrieved_examples\n",
      "        ])\n",
      "    expected_tech = fallback_skills.get(\"technical_skills\", [])\n",
      "    expected_soft = fallback_skills.get(\"soft_skills\", [])\n",
      "\n",
      "    prompt = f\"\"\"\n",
      "        You are a highly experienced career advis ...\n",
      "\n",
      "\n",
      "üîπ Result 52:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " , resources in result[\"action_plan\"].get(key, {}).items():\n",
      "                    html += f\"<li><strong>{skill}</strong><ul>\"\n",
      "                    for item in resources:\n",
      "                        if isinstance(item, dict):\n",
      "                            title = item.get(\"title\", \"\")\n",
      "                          ...\n",
      "\n",
      "\n",
      "üîπ Result 53:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 89-129\n",
      "üìõ Name: generate_skill_gap\n",
      "üß† Content preview:\n",
      " def generate_skill_gap(resume_text, target_role, retrieved_examples, fallback_skills):\n",
      "    examples_prompt = \"\\n\\n\".join([\n",
      "    f\"Example for role {ex['target_role']}:\\nResume: {ex['resume_summary']}\\nSkill Gaps: tech={ex['technical_skill_gap']}, soft={ex['soft_skill_gap']}, transferable={ex['transfe ...\n",
      "\n",
      "\n",
      "üîπ Result 54:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_21\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 21\n",
      "üß† Content preview:\n",
      " mentors_final_data[mentors_final_data[\"cluster\"] == prediction[0]][['name', 'bio','linkedin_id', 'technical_skills']] ...\n",
      "\n",
      "\n",
      "üîπ Result 55:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 37-44\n",
      "üìõ Name: load_examples\n",
      "üß† Content preview:\n",
      " def load_examples():\n",
      "            with open(\"/mount/src/stepupyourcareer.ai/StepUpAI/skill_gap_analysis.json\", \"r\") as f:\n",
      "                examples = json.load(f)\n",
      "            example_texts = [\n",
      "                f\"Resume: {ex['resume_summary']} | Role: {ex['target_role']}\" for ex in examples\n",
      "             ...\n",
      "\n",
      "\n",
      "üîπ Result 56:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\update.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-129\n",
      "üìõ Name: update.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "#\n",
      "# An example hook script to block unannotated tags from entering.\n",
      "# Called by \"git receive-pack\" with arguments: refname sha1-old sha1-new\n",
      "#\n",
      "# To enable this hook, rename this file to \"update\".\n",
      "#\n",
      "# Config\n",
      "# ------\n",
      "# hooks.allowunannotated\n",
      "#   This boolean sets whether unannotated tags wi ...\n",
      "\n",
      "\n",
      "üîπ Result 57:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_11\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 11\n",
      "üß† Content preview:\n",
      " def summarize_resume(resume):\n",
      "    tech_skills = \", \".join(resume.get(\"technical_skills\", []))\n",
      "    soft_skills = \", \".join(resume.get(\"soft_skills\", []))\n",
      "    parts = []\n",
      "    if resume.get(\"education\"):\n",
      "        parts.append(f\"Education: {resume['education']}\")\n",
      "    if resume.get(\"work_experience\"):\n",
      "     ...\n",
      "\n",
      "\n",
      "üîπ Result 58:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_6\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 6\n",
      "üß† Content preview:\n",
      " mentors_final_data = pd.read_json(\"generated_mentors.json\")\n",
      "mentors_final_data.set_index(\"mentor_id\", inplace=True)\n",
      "mentors_final_data.head(5) ...\n",
      "\n",
      "\n",
      "üîπ Result 59:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_12\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 12\n",
      "üß† Content preview:\n",
      " best_k = 29\n",
      "kmeans_final = KMeans(n_clusters=best_k, random_state=42, n_init='auto')\n",
      "mentors_final_data[\"cluster\"] = kmeans_final.fit_predict(skills_df)\n",
      "\n",
      "# Mount Google Drive\n",
      "from google.colab import drive\n",
      "drive.mount('/content/drive')\n",
      "\n",
      "\n",
      "# Define path to save\n",
      "save_path = \"/content/drive/My Drive/sav ...\n",
      "\n",
      "\n",
      "üîπ Result 60:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_3\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 3\n",
      "üß† Content preview:\n",
      " client = OpenAI(api_key=userdata.get(\"Open_AI_API_KEY\")) ...\n",
      "\n",
      "\n",
      "üîπ Result 61:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_2\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 2\n",
      "üß† Content preview:\n",
      " # !pip install PyPDF2 openai\n",
      "import openai\n",
      "import json\n",
      "import time\n",
      "import re\n",
      "from openai import OpenAI\n",
      "from google.colab import userdata\n",
      "import pandas as pd\n",
      "pd.set_option('display.max_colwidth', None)\n",
      "from PyPDF2 import PdfReader\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "import numpy as ...\n",
      "\n",
      "\n",
      "üîπ Result 62:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_7\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 7\n",
      "üß† Content preview:\n",
      " sim_resumes = pd.read_json(\"all_roles_student_resumes.json\") ...\n",
      "\n",
      "\n",
      "üîπ Result 63:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_9\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 9\n",
      "üß† Content preview:\n",
      " sim_resumes.to_json('sim_resume.json', orient='records', lines=False) ...\n",
      "\n",
      "\n",
      "üîπ Result 64:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " _dict(orient=\"records\") if not mentors.empty else []   \n",
      "        }\n",
      "    \n",
      "\n",
      "    def format_result_as_html(result, user_name):\n",
      "            html = f\"<h2>Hi {user_name},</h2>\"\n",
      "            html += f\"<p>Here is your personalized skill gap analysis for the role of <strong>{result['target_role']}</strong>.</p> ...\n",
      "\n",
      "\n",
      "üîπ Result 65:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\pre-applypatch.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-15\n",
      "üìõ Name: pre-applypatch.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "#\n",
      "# An example hook script to verify what is about to be committed\n",
      "# by applypatch from an e-mail message.\n",
      "#\n",
      "# The hook should exit with non-zero status after issuing an\n",
      "# appropriate message if it wants to stop the commit.\n",
      "#\n",
      "# To enable this hook, rename this file to \"pre-applypatch\".\n",
      "\n",
      ".  ...\n",
      "\n",
      "\n",
      "üîπ Result 66:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: sliding_window\n",
      "üî¢ Lines: approx\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " 0,0,0,0.25);\n",
      "                                '>\n",
      "                                    <div>\n",
      "                                        <h4 style='margin-bottom: 5px;'>{mentor['name']}</h4>\n",
      "                                        <p style='margin: 0 0 8px 0; font-size: 0.9em;'>\n",
      "                            ...\n",
      "\n",
      "\n",
      "üîπ Result 67:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_3\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 3\n",
      "üß† Content preview:\n",
      " client = OpenAI(api_key=userdata.get(\"openai_key\")) ...\n",
      "\n",
      "\n",
      "üîπ Result 68:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\push-to-checkout.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-79\n",
      "üìõ Name: push-to-checkout.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "\n",
      "# An example hook script to update a checked-out tree on a git push.\n",
      "#\n",
      "# This hook is invoked by git-receive-pack(1) when it reacts to git\n",
      "# push and updates reference(s) in its repository, and when the push\n",
      "# tries to update the branch that is currently checked out and the\n",
      "# receive.deny ...\n",
      "\n",
      "\n",
      "üîπ Result 69:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_17\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 17\n",
      "üß† Content preview:\n",
      " with open(\"role_skills.json\", \"r\") as f:\n",
      "    resumes_data = json.load(f)\n",
      "\n",
      "print(json.dumps(resumes_data, indent=2)) ...\n",
      "\n",
      "\n",
      "üîπ Result 70:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\pre-merge-commit.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-14\n",
      "üìõ Name: pre-merge-commit.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "#\n",
      "# An example hook script to verify what is about to be committed.\n",
      "# Called by \"git merge\" with no arguments.  The hook should\n",
      "# exit with non-zero status after issuing an appropriate message to\n",
      "# stderr if it wants to stop the merge commit.\n",
      "#\n",
      "# To enable this hook, rename this file to \"p ...\n",
      "\n",
      "\n",
      "üîπ Result 71:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_5\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 5\n",
      "üß† Content preview:\n",
      " from google.colab import sheets\n",
      "sheet = sheets.InteractiveSheet(df=req_jobs_desc) ...\n",
      "\n",
      "\n",
      "üîπ Result 72:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\pre-receive.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-25\n",
      "üìõ Name: pre-receive.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "#\n",
      "# An example hook script to make use of push options.\n",
      "# The example simply echoes all push options that start with 'echoback='\n",
      "# and rejects all pushes when the \"reject\" push option is used.\n",
      "#\n",
      "# To enable this hook, rename this file to \"pre-receive\".\n",
      "\n",
      "if test -n \"$GIT_PUSH_OPTION_COUNT\"\n",
      " ...\n",
      "\n",
      "\n",
      "üîπ Result 73:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_9\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 9\n",
      "üß† Content preview:\n",
      " with open(\"all_roles_student_resumes.json\", \"r\") as f:\n",
      "    resumes = json.load(f)\n",
      "\n",
      "jobs_df = pd.read_csv(\"req_job_desc.csv\") ...\n",
      "\n",
      "\n",
      "üîπ Result 74:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_8\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 8\n",
      "üß† Content preview:\n",
      " sim_resumes.loc[sim_resumes['target_role'] == 'Artificial Intelligence', 'target_role'] = 'AI Engineer' ...\n",
      "\n",
      "\n",
      "üîπ Result 75:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\pre-commit.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-50\n",
      "üìõ Name: pre-commit.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "#\n",
      "# An example hook script to verify what is about to be committed.\n",
      "# Called by \"git commit\" with no arguments.  The hook should\n",
      "# exit with non-zero status after issuing an appropriate message if\n",
      "# it wants to stop the commit.\n",
      "#\n",
      "# To enable this hook, rename this file to \"pre-commit\".\n",
      "\n",
      "if ...\n",
      "\n",
      "\n",
      "üîπ Result 76:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_10\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 10\n",
      "üß† Content preview:\n",
      " k_val = np.arange(10, 30)\n",
      "best_k = None\n",
      "best_score = -1\n",
      "shilloutte_scores = []\n",
      "inertias = []\n",
      "ch_indexs = []\n",
      "\n",
      "for k in k_val:\n",
      "    temp_sil_scores = []\n",
      "    temp_ch_scores = []\n",
      "    temp_inertias = []\n",
      "\n",
      "    for run in range(100):  # 100 is heavy; reduce to 5 or 10 for dev\n",
      "        kmeans = KMeans(n_cluste ...\n",
      "\n",
      "\n",
      "üîπ Result 77:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\applypatch-msg.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-16\n",
      "üìõ Name: applypatch-msg.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "#\n",
      "# An example hook script to check the commit log message taken by\n",
      "# applypatch from an e-mail message.\n",
      "#\n",
      "# The hook should exit with non-zero status after issuing an\n",
      "# appropriate message if it wants to stop the commit.  The hook is\n",
      "# allowed to edit the commit message file.\n",
      "#\n",
      "# To enabl ...\n",
      "\n",
      "\n",
      "üîπ Result 78:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 131-160\n",
      "üìõ Name: get_skill_priorities_from_gpt\n",
      "üß† Content preview:\n",
      " def get_skill_priorities_from_gpt(skills, role):\n",
      "    prompt = f\"\"\"\n",
      "    You are a career advisor. For the target role '{role}', prioritize the following skills based on the 80/20 (Pareto) principle.\n",
      "\n",
      "    Skills:\n",
      "    {', '.join(skills)}\n",
      "\n",
      "    Return JSON mapping each skill to an importance score from 1 ...\n",
      "\n",
      "\n",
      "üîπ Result 79:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\prepare-commit-msg.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-43\n",
      "üìõ Name: prepare-commit-msg.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "#\n",
      "# An example hook script to prepare the commit log message.\n",
      "# Called by \"git commit\" with the name of the file that has the\n",
      "# commit message, followed by the description of the commit\n",
      "# message's source.  The hook's purpose is to edit the commit\n",
      "# message file.  If the hook fails with a  ...\n",
      "\n",
      "\n",
      "üîπ Result 80:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\pre-rebase.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-170\n",
      "üìõ Name: pre-rebase.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "#\n",
      "# Copyright (c) 2006, 2008 Junio C Hamano\n",
      "#\n",
      "# The \"pre-rebase\" hook is run just before \"git rebase\" starts doing\n",
      "# its job, and can prevent the command from running by exiting with\n",
      "# non-zero status.\n",
      "#\n",
      "# The hook is called with the following parameters:\n",
      "#\n",
      "# $1 -- the upstream the series  ...\n",
      "\n",
      "\n",
      "üîπ Result 81:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\pre-push.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-54\n",
      "üìõ Name: pre-push.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "\n",
      "# An example hook script to verify what is about to be pushed.  Called by \"git\n",
      "# push\" after it has checked the remote status, but before anything has been\n",
      "# pushed.  If this script exits with a non-zero status nothing will be pushed.\n",
      "#\n",
      "# This hook is called with the following parameters: ...\n",
      "\n",
      "\n",
      "üîπ Result 82:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 178-186\n",
      "üìõ Name: split_skills_by_rag_presence\n",
      "üß† Content preview:\n",
      " def split_skills_by_rag_presence(skills, rag_skill_keys):\n",
      "    present = []\n",
      "    missing = []\n",
      "    for skill in skills:\n",
      "        if skill.strip().upper() in rag_skill_keys:\n",
      "            present.append(skill)\n",
      "        else:\n",
      "            missing.append(skill)\n",
      "    return present, missing ...\n",
      "\n",
      "\n",
      "üîπ Result 83:\n",
      "üìÑ File: tmp_repo\\.git\\hooks\\commit-msg.sample\n",
      "üìå Type: .sample\n",
      "üî¢ Lines: 1-25\n",
      "üìõ Name: commit-msg.sample\n",
      "üß† Content preview:\n",
      " #!/bin/sh\n",
      "#\n",
      "# An example hook script to check the commit log message.\n",
      "# Called by \"git commit\" with one argument, the name of the file\n",
      "# that has the commit message.  The hook should exit with non-zero\n",
      "# status after issuing an appropriate message if it wants to stop the\n",
      "# commit.  The hook is allow ...\n",
      "\n",
      "\n",
      "üîπ Result 84:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_6\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 6\n",
      "üß† Content preview:\n",
      " uploaded = files.upload()\n",
      "\n",
      "for fn in uploaded.keys():\n",
      "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
      "      name=fn, length=len(uploaded[fn]))) ...\n",
      "\n",
      "\n",
      "üîπ Result 85:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_18\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 18\n",
      "üß† Content preview:\n",
      " #predicting on a student\n",
      "\n",
      "# Load student skill gap\n",
      "student_data = pd.read_json(\"skill_gap_analysis.json\")\n",
      "skill_gap = student_data.iloc[np.random.randint(1)]['technical_skill_gap']\n",
      "\n",
      "skill_gap = [s.strip() for s in skill_gap.split(\",\")]\n",
      "skill_gap\n",
      "\n",
      "# Ensure mlb is already fitted on your mentor skill d ...\n",
      "\n",
      "\n",
      "üîπ Result 86:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: markdown_cell\n",
      "üî¢ Lines: cell_9\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 9\n",
      "üß† Content preview:\n",
      " ### Fitting a KMean model with range of cluster k and ran for 100 times to be certain. ...\n",
      "\n",
      "\n",
      "üîπ Result 87:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 60-62\n",
      "üìõ Name: get_embedding\n",
      "üß† Content preview:\n",
      " def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
      "    response = client.embeddings.create(input=[text], model=model)\n",
      "    return response.data[0].embedding ...\n",
      "\n",
      "\n",
      "üîπ Result 88:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_2\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 2\n",
      "üß† Content preview:\n",
      " from google.colab import files\n",
      "\n",
      "uploaded = files.upload()\n",
      "\n",
      "for fn in uploaded.keys():\n",
      "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
      "      name=fn, length=len(uploaded[fn]))) ...\n",
      "\n",
      "\n",
      "üîπ Result 89:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 65-67\n",
      "üìõ Name: extract_text_from_pdf\n",
      "üß† Content preview:\n",
      " def extract_text_from_pdf(uploaded_file):\n",
      "    reader = PdfReader(uploaded_file)\n",
      "    return \"\\n\".join([page.extract_text() or \"\" for page in reader.pages]) ...\n",
      "\n",
      "\n",
      "üîπ Result 90:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 82-86\n",
      "üìõ Name: retrieve_examples\n",
      "üß† Content preview:\n",
      " def retrieve_examples(query, embeddings, examples, k=3):\n",
      "    query_emb = get_embedding(query)\n",
      "    sims = sk_cosine([query_emb], embeddings)[0]\n",
      "    top_k = sims.argsort()[-k:][::-1]\n",
      "    return [examples[i] for i in top_k] ...\n",
      "\n",
      "\n",
      "üîπ Result 91:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìå Type: code_cell\n",
      "üî¢ Lines: cell_19\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 19\n",
      "üß† Content preview:\n",
      " prediction = kmeans_final.predict(mlb.transform([skill_gap])) ...\n",
      "\n",
      "\n",
      "üîπ Result 92:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 70-79\n",
      "üìõ Name: anonymize\n",
      "üß† Content preview:\n",
      " def anonymize(text):\n",
      "    response = client.chat.completions.create(\n",
      "    model=\"gpt-4o-mini\",\n",
      "    messages=[\n",
      "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that removes personal identifiers from resumes.\"},\n",
      "        {\"role\": \"user\", \"content\": f\"Anonymize this resume:\\n\\n{text}\"}\n",
      "  ...\n",
      "\n",
      "\n",
      "üîπ Result 93:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìå Type: functiondef\n",
      "üî¢ Lines: 164-171\n",
      "üìõ Name: extract_json_from_response\n",
      "üß† Content preview:\n",
      " def extract_json_from_response(raw):\n",
      "    match = re.search(r\"\\{[\\s\\S]*\\}\", raw)\n",
      "    if match:\n",
      "        try:\n",
      "            return json.loads(match.group())\n",
      "        except json.JSONDecodeError:\n",
      "            return {}\n",
      "    return {} ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query for architecture-related info\n",
    "arch_query = \"Architecture Overview\"\n",
    "arch_docs = db.similarity_search(arch_query, k=1000)\n",
    "\n",
    "# Preview content and metadata for each chunk\n",
    "for i, doc in enumerate(arch_docs, start=1):\n",
    "    print(f\"\\nüîπ Result {i}:\")\n",
    "    print(\"üìÑ File:\", doc.metadata.get(\"source\"))\n",
    "    print(\"üìå Type:\", doc.metadata.get(\"type\"))\n",
    "    print(\"üî¢ Lines:\", doc.metadata.get(\"lines\"))\n",
    "    print(\"üìõ Name:\", doc.metadata.get(\"name\"))\n",
    "    print(\"üß† Content preview:\\n\", doc.page_content[:300], \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0c76a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Job_Description_JD_Manupulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4cbd7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "relevance_judgments = []\n",
    "\n",
    "for i, chunk in enumerate(arch_docs):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert documentation reviewer.\n",
    "\n",
    "Your task is to **judge** whether the following chunk is relevant to writing the section:  \n",
    "**\"{arch_query}\"**\n",
    "\n",
    "üìå Rules:\n",
    "- Prioritise **code cells**, functions, or implementation details over high-level marketing or introductory text (e.g., README).\n",
    "- Only select markdown if it describes a technical process, setup instruction, or logic explanation.\n",
    "- then understand the code or text and then tell if this can be used to generate the documentation.\n",
    "- Return a JSON with only the following fields: `chunk_id`, `relevant`, and `reason`.\n",
    "- `chunk_id` is the numeric index: {i}\n",
    "- If the chunk is related to {arch_query}, set `\"relevant\": true` and give a brief reason.\n",
    "- If not, set `\"relevant\": false` and explain why.\n",
    "- Do **not** repeat the chunk content.\n",
    "- Keep the explanation short and factual.\n",
    "\n",
    "Example:\n",
    "{{\n",
    "  \"chunk_id\": 3,\n",
    "  \"relevant\": true,\n",
    "  \"reason\": \"Loads required JSON files for skill gap analysis, which is part of setup.\"\n",
    "}}\n",
    "\n",
    "Evaluate this chunk:\n",
    "{chunk.page_content}\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.5,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content.strip()\n",
    "    \n",
    "    try:\n",
    "        # Optionally use json.loads() if you're confident it's valid JSON\n",
    "        relevance_judgments.append({\n",
    "            \"chunk_id\": i,\n",
    "            \"relevant\": '\"relevant\": true' in result.lower(),\n",
    "            \"reason\": result.split('\"reason\":', 1)[-1].strip().rstrip('}').strip('\"')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse chunk {i}: {e}\")\n",
    "        relevance_judgments.append({\n",
    "            \"chunk_id\": i,\n",
    "            \"relevant\": False,\n",
    "            \"reason\": \"Parsing failed or invalid format.\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0816371e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 12,\n",
       "  'relevant': True,\n",
       "  'reason': 'Contains implementation details for analyzing resumes and generating skill gaps, which are key components of the system architecture.\"\\n'},\n",
       " {'chunk_id': 13,\n",
       "  'relevant': True,\n",
       "  'reason': 'Contains implementation details for sending emails and formatting results, which are part of the system\\'s architecture and functionality.\"\\n'},\n",
       " {'chunk_id': 14,\n",
       "  'relevant': True,\n",
       "  'reason': 'Includes code for loading data, analyzing resumes, and generating skill gap analysis, detailing the system\\'s functionality and architecture.\"\\n'},\n",
       " {'chunk_id': 16,\n",
       "  'relevant': True,\n",
       "  'reason': 'The function details the process of generating a hybrid action plan, including skill categorization and resource extraction, which are key components of the system architecture.\"\\n'},\n",
       " {'chunk_id': 17,\n",
       "  'relevant': True,\n",
       "  'reason': 'Contains functions and implementation details related to skill prioritization and resource loading, which are part of the system\\'s architecture.\"\\n'},\n",
       " {'chunk_id': 18,\n",
       "  'relevant': True,\n",
       "  'reason': 'Contains implementation details for generating and displaying a hybrid action plan, which is part of the system\\'s architecture.\"\\n'}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in relevance_judgments if i['relevant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "26b078a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Result 12:\n",
      "üìÑ File: tmp_repo\\Job_Description_JD_Manupulation.ipynb\n",
      "üìõ Name: Job_Description_JD_Manupulation.ipynb - cell 0\n",
      "üß† Content preview:\n",
      " <a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Job_Description_JD_Manupulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> ...\n",
      "\n",
      "\n",
      "üîπ Result 13:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 0\n",
      "üß† Content preview:\n",
      " <a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUp-AI/blob/main/Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> ...\n",
      "\n",
      "\n",
      "üîπ Result 14:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 23\n",
      "üß† Content preview:\n",
      " ### Action Plan Generation (Testing for 3 Candidates) ...\n",
      "\n",
      "\n",
      "üîπ Result 15:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 16\n",
      "üß† Content preview:\n",
      " ### File containing all common skills required for a particular role ...\n",
      "\n",
      "\n",
      "üîπ Result 16:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 12\n",
      "üß† Content preview:\n",
      " ### Printing 120 job descriptions for each role (Total 600) ...\n",
      "\n",
      "\n",
      "üîπ Result 17:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 14\n",
      "üß† Content preview:\n",
      " ### Extracting common required technical and soft skills required for each role. ...\n",
      "\n",
      "\n",
      "üîπ Result 18:\n",
      "üìÑ File: tmp_repo\\README.md\n",
      "üìõ Name: README.md\n",
      "üß† Content preview:\n",
      " # StepUpYourCareer.ai: Elevate Your Future\n",
      "\n",
      "An AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\n",
      "\n",
      "### Link to the website: https://stepupyourcareer.streamlit.app/\n",
      "\n",
      "---\n",
      "\n",
      "## Problem\n",
      "\n",
      "Graduates often leave university with degrees but **lack clarity on what employers actually expect**. They spend months applying for jobs, facing rejections without knowing **what skills they‚Äôre missing** or **how to upskill efficiently**.\n",
      "\n",
      "---\n",
      "\n",
      "## Solution\n",
      "\n",
      "**StepUpYourCareer.ai** transforms your resume into a personalized upskilling journey.\n",
      "\n",
      "- **Skill Gap Analyzer**: Extracts skills from your resume and compares them to your target role\n",
      "- **Action Plan Generator**: Recommends curated online courses and resources for each missing skill\n",
      "- **Mentor Matching**: Clusters users and mentors using K-Means to connect you with experts in your domain\n",
      "\n",
      "---\n",
      "\n",
      "![Notes_250516_042908_1](https://github.com/user-attachments/assets/a42216a8-e04c-4335-aad7-d56a61cc873b)\n",
      "\n",
      "![Notes_250516_042908_4](https://github.com/user-attachments/assets/ba3b34ec-57ec-4bf5-906a-84af82342b8b)\n",
      "\n",
      "![Notes_250516_042908_3](https://github.com/user-attachments/assets/4b7e5f11-7923-427c-be95-cbcd7d919c5b)\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      "üîπ Result 19:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 20\n",
      "üß† Content preview:\n",
      " ### Skill Gap Analysis Functionality - allows user to upload their resume ...\n",
      "\n",
      "\n",
      "üîπ Result 20:\n",
      "üìÑ File: tmp_repo\\README.md\n",
      "üìõ Name: README.md\n",
      "üß† Content preview:\n",
      " # StepUpYourCareer.ai: Elevate Your Future\n",
      "\n",
      "An AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\n",
      "\n",
      "### Link to the website: https://stepupyourcareer.streamlit.app/\n",
      "\n",
      "---\n",
      "\n",
      "## Problem\n",
      "\n",
      "Graduates often leave university with degrees but **lack clarity on what employers actually expect**. They spend months applying for jobs, facing rejections without knowing **what skills they‚Äôre missing** or **how to upskill efficiently**.\n",
      "\n",
      "---\n",
      "\n",
      "## Solution\n",
      "\n",
      "**StepUpYourCareer.ai** transforms your resume into a personalized upskilling journey.\n",
      "\n",
      "- **Skill Gap Analyzer**: Extracts skills from your resume and compares them to your target role\n",
      "- **Action Plan Generator**: Recommends curated online courses and resources for each missing skill\n",
      "- **Mentor Matching**: Clusters users and mentors using K-Means to connect you with experts in your domain\n",
      "\n",
      "---\n",
      "\n",
      "![Notes_250516_042908_1](https://github.com/user-attachments/assets/a42216a8-e04c-4335-aad7-d56a61cc873b)\n",
      "\n",
      "![Notes_250516_042908_4](https://github.com/user-attachments/assets/ba3b34ec-57ec-4bf5-906a-84af82342b8b)\n",
      "\n",
      "![Notes_250516_042908_3](https://github.com/user-attachments/assets/4b7e5f11-7923-427c-be95-cbcd7d919c5b) ...\n",
      "\n",
      "\n",
      "üîπ Result 21:\n",
      "üìÑ File: tmp_repo\\README.md\n",
      "üìõ Name: README.md\n",
      "üß† Content preview:\n",
      " # StepUpYourCareer.ai: Elevate Your Future\n",
      "\n",
      "An AI-powered career assistant that helps students and job seekers identify **skill gaps**, receive **personalized learning roadmaps**, and connect with **industry mentors**‚Äîall from a single resume upload.\n",
      "\n",
      "### Link to the website: https://stepupyourcareer.streamlit.app/\n",
      "\n",
      "---\n",
      "\n",
      "## Problem\n",
      "\n",
      "Graduates often leave university with degrees but **lack clarity on what employers actually expect**. They spend months applying for jobs, facing rejections without knowing **what skills they‚Äôre missing** or **how to upskill efficiently**.\n",
      "\n",
      "---\n",
      "\n",
      "## Solution\n",
      "\n",
      "**StepUpYourCareer.ai** transforms your resume into a personalized upskilling journey.\n",
      "\n",
      "- **Skill Gap Analyzer**: Extracts skills from your resume and compares them to your target role\n",
      "- **Action Plan Generator**: Recommends curated online courses and resources for each missing skill\n",
      "- **Mentor Matching**: Clusters users and mentors using K-Means to connect you with experts in your domain\n",
      "\n",
      "---\n",
      "\n",
      "![Notes_250516_042908_1](https://github.com/user-attachments/assets/a42216a8-e04c-4335-aad7-d56a61cc873b)\n",
      "\n",
      "![Notes_250516_042908_4](https://github.com/user-attachments/assets/ba3b34ec-57ec-4bf5-906a-84af82342b8b)\n",
      "\n",
      "![Notes_250516_042908_3](https://github.com/user-attachments/assets/4b7e5f11-7923-427c-be95-cbcd7d919c5b) ...\n",
      "\n",
      "\n",
      "üîπ Result 22:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 0\n",
      "üß† Content preview:\n",
      " <a href=\"https://colab.research.google.com/github/adarshlearnngrow/StepUpYourCareer.AI/blob/Clustering/ClusteringMentorModelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> ...\n",
      "\n",
      "\n",
      "üîπ Result 23:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 4\n",
      "üß† Content preview:\n",
      " ## Prompt to generate Mentors with skills of experties ...\n",
      "\n",
      "\n",
      "üîπ Result 24:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " upyourcareer.ai/StepUpAI/mentors_final_data.json\")\n",
      "\n",
      "def page_2():\n",
      "    st.title(\"üìÑ Resume Analyzer + Mentor Recommender\")\n",
      "    st.markdown(f\"**üë§ Name:** {st.session_state.name}  |  **üìß Email:** {st.session_state.email}\")\n",
      "\n",
      "    st.markdown(\"Please ensure your resume reflects your true skills and experiences ‚Äî being honest helps us generate the most accurate and helpful guidance for your growth.\")\n",
      "\n",
      "    uploaded_file = st.file_uploader(\"üìÑ Upload your resume (PDF)\", type=[\"pdf\"])\n",
      "    target_role = st.selectbox(\"üéØ Select your target role\", [\n",
      "        \"AI Engineer\", \"Data Analyst\", \"Business Analyst\",\n",
      "        \"Business Intelligence Analyst\", \"Machine Learning\"\n",
      "    ])\n",
      "    if st.button(\"üîç Analyze Resume\") and uploaded_file and target_role:\n",
      "        st.info(\"Processing resume... Please wait.\")\n",
      "\n",
      "        resume_text = extract_text_from_pdf(uploaded_file)\n",
      "        anonymized_resume = anonymize(resume_text)\n",
      "\n",
      "        examples, example_embeddings = load_examples()\n",
      "        skills_dict = load_role_skills()\n",
      "        fallback_skills = skills_dict.get(target_role, {})\n",
      "        query = f\"Resume: {anonymized_resume} | Role: {target_role}\"\n",
      "        retrieved = retrieve_examples(query, example_embeddings, examples)\n",
      "\n",
      "        gaps = generate_skill_gap(anonymized_resume, target_role, retrieved, fallback_skills)\n",
      "\n",
      "        all_skills = list(set(gaps[\"technical_skill_gaps\"] + gaps[\"soft_skill_gaps\"] + gaps[\"transferable_skills\"]))\n",
      "        skill_priorities = get_skill_priorities_from_gpt(all_skills, target_role)\n",
      "\n",
      "       \n",
      "\n",
      "        # Sort gaps by importance\n",
      "        gaps[\"technical_skill_gaps\"] = sorted(gaps[\"technical_skill_gaps\"], key=lambda x: -skill_priorities.get(x, 0))\n",
      "        gaps[\"soft_skill_gaps\"] = sorted(gaps[\"soft_skill_gaps\"], key=lambda x: -skill_priorities.get(x, 0))\n",
      "        gaps[\"transferable_skills\"] = sorted(gaps[\"transferable_skills\"], key=lambda x: -skill_priorities.get(x, 0))\n",
      "\n",
      "        st.success(\"Analysis complete!\")\n",
      "\n",
      "        st.subheader(\"üîç Skill Gap Summary\")\n",
      "        gap_cols_html = \"\"\"\n",
      "        <div style='display: flex; gap: 20px;'>\n",
      "            <div style='flex: 1; padding: 20px; border-radius: 12px; box-shadow: 0  ...\n",
      "\n",
      "\n",
      "üîπ Result 25:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      "  = m.get(\"bio\", \"N/A\")\n",
      "                    linkedin = m.get(\"linkedin_id\", \"\")\n",
      "                    html += f\"\"\"\n",
      "                    <tr>\n",
      "                        <td>{name}</td>\n",
      "                        <td>{skills}</td>\n",
      "                        <td>{bio}</td>\n",
      "                        <td><a href=\"https://www.linkedin.com/in/{linkedin}\" target=\"_blank\">üîó</a></td>\n",
      "                    </tr>\n",
      "                    \"\"\"\n",
      "                html += \"</table>\"\n",
      "            else:\n",
      "                html += \"<p>No mentor matches found.</p>\"\n",
      "\n",
      "            html += \"<p>Best of luck!<br/>‚Äì StepUpYourCareer.AI</p>\"\n",
      "            return html\n",
      "        \n",
      "    def send_email(to_email, subject, html_content):\n",
      "            from email.mime.multipart import MIMEMultipart\n",
      "            from email.mime.text import MIMEText\n",
      "            import smtplib\n",
      "\n",
      "            from_email = st.secrets[\"EMAIL_USERNAME\"]\n",
      "            password = st.secrets[\"EMAIL_PASSWORD\"]\n",
      "\n",
      "            msg = MIMEMultipart(\"alternative\")\n",
      "            msg[\"Subject\"] = subject\n",
      "            msg[\"From\"] = from_email\n",
      "            msg[\"To\"] = to_email\n",
      "\n",
      "            part = MIMEText(html_content, \"html\")\n",
      "            msg.attach(part)\n",
      "\n",
      "            with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
      "                server.login(from_email, password)\n",
      "                server.sendmail(from_email, to_email, msg.as_string())\n",
      "\n",
      "        \n",
      "    if \"result\" in st.session_state:\n",
      "        if st.button(\"üìß Email Me the Results\"):\n",
      "            try:\n",
      "                email_html = format_result_as_html(st.session_state.result, st.session_state.name)\n",
      "                send_email(st.session_state.email, f\"Your Skill Gap Report for {st.session_state.result['target_role']}\", email_html)\n",
      "                st.success(\"Email sent successfully!\")\n",
      "            except Exception as e:\n",
      "                st.error(f\"Failed to send email: {e}\")\n",
      "\n",
      "\n",
      "\n",
      "# === Page Router ===\n",
      "if st.session_state.page == 1:\n",
      "    page_1()\n",
      "elif st.session_state.page == 2:\n",
      "    page_2()\n",
      " ...\n",
      "\n",
      "\n",
      "üîπ Result 26:\n",
      "üìÑ File: tmp_repo\\Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb\n",
      "üìõ Name: Skill_Gap_Analysis_and_Action_Plan_Generation.ipynb - cell 19\n",
      "üß† Content preview:\n",
      " # Load Files\n",
      "with open(\"sim_resume.json\", \"r\") as f:\n",
      "    resumes = [json.loads(line) for line in f]\n",
      "\n",
      "with open(\"role_skills.json\", \"r\") as f:\n",
      "    raw_roles = json.load(f)\n",
      "role_skills = {r[\"role\"]: r for r in raw_roles}\n",
      "\n",
      "# Helper Functions\n",
      "def summarize_resume(resume):\n",
      "    \"\"\"Summarize fields from a student resume.\"\"\"\n",
      "    summary = []\n",
      "    if \"target_role\" in resume:\n",
      "        summary.append(f\"Target Role: {resume['target_role']}\")\n",
      "    if \"education\" in resume:\n",
      "        summary.append(f\"Education: {resume['education']}\")\n",
      "    if \"work_experience\" in resume:\n",
      "        jobs = [w[\"role\"] for w in resume[\"work_experience\"] if \"role\" in w]\n",
      "        if jobs:\n",
      "            summary.append(\"Experience: \" + \", \".join(jobs))\n",
      "    if \"technical_skills\" in resume:\n",
      "        summary.append(\"Technical Skills: \" + \", \".join(resume[\"technical_skills\"]))\n",
      "    if \"soft_skills\" in resume:\n",
      "        summary.append(\"Soft Skills: \" + \", \".join(resume[\"soft_skills\"]))\n",
      "    return \" | \".join(summary)\n",
      "\n",
      "def generate_skill_gap(resume_text, expected_tech, expected_soft):\n",
      "    \"\"\"Query OpenAI to get skill gaps and transferable skills.\"\"\"\n",
      "    prompt = f\"\"\"\n",
      "You are a career advisor helping students identify skill gaps.\n",
      "\n",
      "Compare the student's resume with the required skills below. Do 3 things:\n",
      "\n",
      "1. Identify missing **technical skills** from the list that are not in the resume.\n",
      "2. Identify missing **soft skills** from the list.\n",
      "3. Suggest **transferable skills** from the resume that could help the student learn the missing technical skills.\n",
      "\n",
      "Return valid JSON with this structure:\n",
      "{{\n",
      "  \"technical_skill_gaps\": [...],\n",
      "  \"soft_skill_gaps\": [...],\n",
      "  \"transferable_skills\": [...]\n",
      "}}\n",
      "\n",
      "If a category is empty, return an empty list.\n",
      "Do NOT explain or repeat anything. Just return clean JSON.\n",
      "\n",
      "---\n",
      "Resume:\n",
      "{resume_text}\n",
      "\n",
      "Required Technical Skills: {\", \".join(expected_tech)}\n",
      "Required Soft Skills: {\", \".join(expected_soft)}\n",
      "\"\"\"\n",
      "\n",
      "    try:\n",
      "        response = client.chat.completions.create(\n",
      "            model=\"gpt-4o-mini\",\n",
      "            messages=[\n",
      "                {\"role\": \"system\", \"content\": \"You are a helpful assistant for skill gap analysis.\"},\n",
      "                {\"role\": \"user\", \"content\": prompt}\n",
      "            ],\n",
      "            temperature=0\n",
      "        )\n",
      "        result = response.choices[0].message.content.strip()\n",
      "\n",
      "        if result.startswith(\"```json\"):\n",
      "            result = result[7:]\n",
      "        if result.endswith(\"```\"):\n",
      "            result = result[:-3]\n",
      "\n",
      "        parsed = json.loads(result)\n",
      "        return (\n",
      "            parsed.get(\"technical_skill_gaps\", []),\n",
      "            parsed.get(\"soft_skill_gaps\", []),\n",
      "            parsed.get(\"transferable_skills\", [])\n",
      "        )\n",
      "    except Exception as e:\n",
      "        print(\"Error:\", e)\n",
      "        return [], [], []\n",
      "\n",
      "# Run Analysis\n",
      "\n",
      "records = []\n",
      "\n",
      "for idx, resume in enumerate(resumes):\n",
      "    name = resume.get(\"name\", f\"Candidate_{idx}\")\n",
      "    role = resume.get(\"target_role\", \"\").strip()\n",
      "\n",
      "    if not role or role not in role_skills:\n",
      "        print(f\"[{name}] Skipped ‚Äî no target role or unknown role.\")\n",
      "        continue\n",
      "\n",
      "    resume_summary = summarize_resume(resume)\n",
      "    expected = role_skills[role]\n",
      "    tech_skills = expected[\"technical_skills\"]\n",
      "    soft_skills = expected[\"soft_skills\"]\n",
      "\n",
      "    print(f\"[{name}] ‚Üí Analyzing role: {role}\")\n",
      "    tech_gap, soft_gap, transferable = generate_skill_gap(resume_summary, tech_skills, soft_skills)\n",
      "\n",
      "    records.append({\n",
      "        \"name\": name,\n",
      "        \"target_role\": role,\n",
      "        \"resume_summary\": resume_summary,\n",
      "        \"technical_skill_gap\": \", \".join(tech_gap),\n",
      "        \"soft_skill_gap\": \", \".join(soft_gap),\n",
      "        \"transferable_skills\": \", \".join(transferable)\n",
      "    })\n",
      "    time.sleep(1)\n",
      "\n",
      "# Save Output\n",
      "df = pd.DataFrame(records)\n",
      "df.to_csv(\"skill_gap_analysis.csv\", index=False)\n",
      "df.to_json(\"skill_gap_analysis.json\", orient=\"records\", indent=2)\n",
      "print(f\"\\n Done! Analyzed {len(records)} resumes and saved to CSV and JSON.\") ...\n",
      "\n",
      "\n",
      "üîπ Result 27:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìõ Name: page_1\n",
      "üß† Content preview:\n",
      " def page_1():\n",
      "    st.title(\"Welcome to StepUpYourCareer.AI\")\n",
      "    st.markdown(\"##### Let's get started with a few details.\")\n",
      "\n",
      "    name = st.text_input(\"Your Full Name\")\n",
      "    email = st.text_input(\"Your Email Address\")\n",
      "\n",
      "    if name and email:\n",
      "        if st.button(\"‚û°Ô∏è Proceed to Resume Analysis\"):\n",
      "            st.session_state.name = name\n",
      "            st.session_state.email = email\n",
      "            st.session_state.page = 2 ...\n",
      "\n",
      "\n",
      "üîπ Result 28:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìõ Name: generate_hybrid_action_plan\n",
      "üß† Content preview:\n",
      " def generate_hybrid_action_plan(tech, soft, trans, skill_resources):\n",
      "    # Split all three skill types\n",
      "    tech_in, tech_out = split_skills_by_rag_presence(tech, skill_resources.keys())\n",
      "    soft_in, soft_out = split_skills_by_rag_presence(soft, skill_resources.keys())\n",
      "    trans_in, trans_out = split_skills_by_rag_presence(trans, skill_resources.keys())\n",
      "\n",
      "    #  Construct RAG results\n",
      "    def extract_rag(skills):\n",
      "        result = {}\n",
      "        for s in skills:\n",
      "            key = s.strip().upper()\n",
      "            if key in skill_resources:\n",
      "                    result[s] = skill_resources[key]\n",
      "        return result\n",
      "\n",
      "    plan = {\n",
      "            \"message\": \"Here's a complete roadmap with relevant resources\",\n",
      "            \"technical_skill_resources\": extract_rag(tech_in),\n",
      "            \"soft_skill_resources\": extract_rag(soft_in),\n",
      "            \"transferable_skill_resources\": extract_rag(trans_in)\n",
      "    }\n",
      "\n",
      "    # Prepare GPT prompt only for uncovered skills\n",
      "    if tech_out or soft_out or trans_out:\n",
      "        prompt = f\"\"\"\n",
      "        You are a career coach. Only generate resources for the following skills not found in our internal library.\n",
      "\n",
      "        Provide for each:\n",
      "        - One **top-rated course** with real working URL.\n",
      "        - One **real book** just name & author and AMAZON links for buying that book.\n",
      "        - For soft/transferable skills, one article or video (with URL).\n",
      "\n",
      "        Format your response in JSON like this:\n",
      "        {{\n",
      "        \"technical_skill_resources\": {{\n",
      "            \"Skill\": [{{\"title\": \"...\", \"url\": \"...\" }}, {{\"title\": \"Book by Author\"}}]\n",
      "        }},\n",
      "        \"soft_skill_resources\": {{\n",
      "            \"Skill\": [{{\"title\": \"...\", \"url\": \"...\" }}]\n",
      "        }},\n",
      "        \"transferable_skill_resources\": {{\n",
      "            \"Skill\": [{{\"title\": \"...\", \"url\": \"...\" }}]\n",
      "        }}\n",
      "        }}\n",
      "\n",
      "        Only cover these:\n",
      "        - TECHNICAL: {', '.join(tech_out)}\n",
      "        - SOFT: {', '.join(soft_out)}\n",
      "        - TRANSFERABLE: {', '.join(trans_out)}\n",
      "\n",
      "        You will be penalized if you confabulate or hallucinate by creating fake resources. It should be 100% authenthic.\n",
      "        Double check every link/resource you give. If you don't get any links leave that section blank.\n",
      "        No explanations. No markdown. Only JSON.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            response = client.chat.completions.create(\n",
      "            # Change to GPT 4 to get accurate links to resources\n",
      "            model=\"gpt-4o-mini\",\n",
      "            messages=[\n",
      "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant for learning.\"},\n",
      "                    {\"role\": \"user\", \"content\": prompt}\n",
      "                    ],\n",
      "                    temperature=0.2\n",
      "                    )\n",
      "            raw = response.choices[0].message.content.strip()\n",
      "            raw = re.sub(r\"```json|```\", \"\", raw)\n",
      "            gpt_part = extract_json_from_response(raw)\n",
      "\n",
      "            if not isinstance(gpt_part, dict):\n",
      "                gpt_part = {}\n",
      "\n",
      "            # Merge GPT results into RAG base\n",
      "            for k in [\"technical_skill_resources\", \"soft_skill_resources\", \"transferable_skill_resources\"]:\n",
      "                if k in gpt_part and isinstance(plan.get(k), dict):\n",
      "                    plan[k].update(gpt_part[k])\n",
      "\n",
      "\n",
      "        except Exception as e:\n",
      "                st.error(f\"Error generating GPT fallback plan: {e}\")\n",
      "\n",
      "        return plan ...\n",
      "\n",
      "\n",
      "üîπ Result 29:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " \": prompt}],\n",
      "        temperature=0.0\n",
      "        )\n",
      "    raw = response.choices[0].message.content.strip()\n",
      "    raw = re.sub(r\"```json|```\", \"\", raw)\n",
      "    return json.loads(raw)\n",
      "\n",
      "def get_skill_priorities_from_gpt(skills, role):\n",
      "    prompt = f\"\"\"\n",
      "    You are a career advisor. For the target role '{role}', prioritize the following skills based on the 80/20 (Pareto) principle.\n",
      "\n",
      "    Skills:\n",
      "    {', '.join(skills)}\n",
      "\n",
      "    Return JSON mapping each skill to an importance score from 1 to 100 (higher means more important). Output should look like:\n",
      "    {{\n",
      "      \"Skill1\": 95,\n",
      "      \"Skill2\": 90,\n",
      "      ...\n",
      "    }}\n",
      "\n",
      "    No explanation. No markdown. Only JSON.\n",
      "    \"\"\"\n",
      "    response = client.chat.completions.create(\n",
      "        model=\"gpt-4o-mini\",\n",
      "        messages=[\n",
      "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that ranks skills by importance.\"},\n",
      "            {\"role\": \"user\", \"content\": prompt}\n",
      "        ],\n",
      "        temperature=0.2\n",
      "    )\n",
      "    raw = response.choices[0].message.content.strip()\n",
      "    raw = re.sub(r\"```json|```\", \"\", raw)\n",
      "    try:\n",
      "        return json.loads(raw)\n",
      "    except json.JSONDecodeError:\n",
      "        return {}\n",
      "\n",
      "\n",
      "# Action Plan Generator\n",
      "def extract_json_from_response(raw):\n",
      "    match = re.search(r\"\\{[\\s\\S]*\\}\", raw)\n",
      "    if match:\n",
      "        try:\n",
      "            return json.loads(match.group())\n",
      "        except json.JSONDecodeError:\n",
      "            return {}\n",
      "    return {}\n",
      "\n",
      "def load_skill_resources():\n",
      "    with open(\"/mount/src/stepupyourcareer.ai/StepUpAI/skill_resource_mapping.json\", \"r\") as f:\n",
      "        return json.load(f)\n",
      "\n",
      "# Helper: Split skill lists into (in-RAG, out-of-RAG) \n",
      "def split_skills_by_rag_presence(skills, rag_skill_keys):\n",
      "    present = []\n",
      "    missing = []\n",
      "    for skill in skills:\n",
      "        if skill.strip().upper() in rag_skill_keys:\n",
      "            present.append(skill)\n",
      "        else:\n",
      "            missing.append(skill)\n",
      "    return present, missing\n",
      "\n",
      "def generate_hybrid_action_plan(tech, soft, trans, skill_resources):\n",
      "    # Split all three skill types\n",
      "    tech_in, tech_out = split_skills_by_rag_presence(tech, skill_resources.keys())\n",
      "    soft_in, soft_out = split_skills_by_rag_presence(soft, ...\n",
      "\n",
      "\n",
      "üîπ Result 30:\n",
      "üìÑ File: tmp_repo\\StepUpAI\\app.py\n",
      "üìõ Name: app.py\n",
      "üß† Content preview:\n",
      " 3 distinct skill names\n",
      "        top_skills = []\n",
      "        for s in ranked_skills:\n",
      "            if s not in top_skills:\n",
      "                top_skills.append(s)\n",
      "            if len(top_skills) == 3:\n",
      "                break\n",
      "\n",
      "        # Show top 3\n",
      "        for i, skill in enumerate(top_skills, 1):\n",
      "            st.markdown(f\"**{i}. {skill}** ‚Äì Priority Score: {skill_priorities.get(skill, 'N/A')}\")\n",
      "            \n",
      "        skill_resources = load_skill_resources()\n",
      "        plan = generate_hybrid_action_plan(tech, soft, trans, skill_resources)\n",
      "\n",
      "        st.info(plan.get(\"message\", \"Here are some great learning resources!\"))\n",
      "        def render_resources_flex(title, resources):\n",
      "            if resources:\n",
      "                st.markdown(f\"<h4 style='margin-top:30px;'>{title}</h4>\", unsafe_allow_html=True)\n",
      "                box_html = \"<div style='display: flex; flex-wrap: wrap; gap: 20px;'>\"\n",
      "                for skill, items in resources.items():\n",
      "                    item_html = f\"<div style='flex: 1 1 calc(33% - 20px); min-width: 300px; padding: 20px; border-radius: 12px; background-color: #1e1e1e; box-shadow: 0 4px 12px rgba(0,0,0,0.25); color: white;'>\"\n",
      "                    item_html += f\"<h5 style='font-size: 1.2rem; margin-bottom: 10px;'>{skill}</h5><ul style='margin-top: 10px;'>\"\n",
      "                    for item in items:\n",
      "                        if isinstance(item, dict):\n",
      "                            title = item.get(\"title\", \"\")\n",
      "                            url = item.get(\"url\", \"\")\n",
      "                            if url:\n",
      "                                item_html += f\"<li><a href='{url}' target='_blank' style='color: #1e90ff;'>{title}</a></li>\"\n",
      "                            else:\n",
      "                                item_html += f\"<li>{title}</li>\"\n",
      "                        elif isinstance(item, str):\n",
      "                            item_html += f\"<li>{item}</li>\"\n",
      "                    item_html += \"</ul></div>\"\n",
      "                    box_html += item_html\n",
      "                box_html += \"</div>\"\n",
      "                st.markdown(box_html, unsafe_allow_html=True)\n",
      "\n",
      "        render_resources_flex(\"üõ†Ô∏è Technical Skills\", plan.get(\"technical_skill_resources\", {}))\n",
      "        render_resources_flex(\"üí¨ Soft Skills\", plan.get(\" ...\n",
      "\n",
      "\n",
      "üîπ Result 31:\n",
      "üìÑ File: tmp_repo\\ClusteringMentorModelTraining.ipynb\n",
      "üìõ Name: ClusteringMentorModelTraining.ipynb - cell 14\n",
      "üß† Content preview:\n",
      " ### Using TSNE to see if the clustering algorithm is grouping based on skills or based on roles ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(arch_docs, start=12):\n",
    "    print(f\"\\nüîπ Result {i}:\")\n",
    "    print(\"üìÑ File:\", doc.metadata.get(\"source\"))\n",
    "\n",
    "\n",
    "    print(\"üìõ Name:\", doc.metadata.get(\"name\"))\n",
    "    print(\"üß† Content preview:\\n\", doc.page_content, \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84edf3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5513a2f5",
   "metadata": {},
   "source": [
    "# maybe we can use this deterministic approach to fethc folder structure instead of LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_clean_repo_tree(repo_path):\n",
    "    exclude_dirs = {'.git', '.devcontainer', '__pycache__', '.ipynb_checkpoints'}\n",
    "    exclude_ext = {'.pdf', '.png', '.jpg', '.jpeg', '.log', '.tmp'}\n",
    "\n",
    "    tree_lines = []\n",
    "\n",
    "    for root, dirs, files in os.walk(repo_path):\n",
    "        # Remove excluded dirs\n",
    "        dirs[:] = [d for d in dirs if d not in exclude_dirs]\n",
    "\n",
    "        # Relative indent\n",
    "        indent_level = root.replace(repo_path, \"\").count(os.sep)\n",
    "        indent = \"    \" * indent_level\n",
    "        tree_lines.append(f\"{indent}{os.path.basename(root)}/\")\n",
    "\n",
    "        for f in files:\n",
    "            ext = os.path.splitext(f)[1].lower()\n",
    "            if f.startswith('.') or ext in exclude_ext:\n",
    "                continue  # skip hidden/unwanted files\n",
    "            tree_lines.append(f\"{indent}    {f}\")\n",
    "\n",
    "    return \"\\n\".join(tree_lines)\n",
    "\n",
    "# ‚úÖ Generate a clean repo tree\n",
    "repo_tree = generate_clean_repo_tree(\"tmp_repo\")\n",
    "print(repo_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc0fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import ast\n",
    "import nbformat\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def extract_chunks(repo_path: str):\n",
    "    all_chunks = []\n",
    "    ast_chunks = []\n",
    "\n",
    "    for filepath in Path(repo_path).rglob(\"*.*\"):\n",
    "        try:\n",
    "            if filepath.suffix == \".py\":\n",
    "                code = filepath.read_text(encoding=\"utf-8\")\n",
    "                tree = ast.parse(code)\n",
    "\n",
    "                mod_doc = ast.get_docstring(tree)\n",
    "                if mod_doc and 50 < len(mod_doc) < 5000:\n",
    "                    doc = Document(\n",
    "                        page_content=mod_doc,\n",
    "                        metadata={\n",
    "                            \"source\": str(filepath),\n",
    "                            \"type\": \"module_docstring\",\n",
    "                            \"name\": filepath.name,\n",
    "                            \"lines\": \"1-{}\".format(code.count(\"\\n\") + 1)\n",
    "                        }\n",
    "                    )\n",
    "                    all_chunks.append(doc)\n",
    "                    ast_chunks.append(doc)\n",
    "\n",
    "                for node in tree.body:\n",
    "                    if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "                        content = ast.get_source_segment(code, node)\n",
    "                        if content and 50 < len(content) < 5000:\n",
    "                            chunk = Document(\n",
    "                                page_content=content,\n",
    "                                metadata={\n",
    "                                    \"source\": str(filepath),\n",
    "                                    \"type\": type(node).__name__.lower(),\n",
    "                                    \"name\": node.name,\n",
    "                                    \"lines\": f\"{node.lineno}-{getattr(node, 'end_lineno', node.lineno)}\"\n",
    "                                }\n",
    "                            )\n",
    "                            all_chunks.append(chunk)\n",
    "                            ast_chunks.append(chunk)\n",
    "\n",
    "                        doc = ast.get_docstring(node)\n",
    "                        if doc and 50 < len(doc) < 5000:\n",
    "                            doc_chunk = Document(\n",
    "                                page_content=doc,\n",
    "                                metadata={\n",
    "                                    \"source\": str(filepath),\n",
    "                                    \"type\": f\"{type(node).__name__.lower()}_docstring\",\n",
    "                                    \"name\": node.name,\n",
    "                                    \"lines\": f\"{node.lineno}-{getattr(node, 'end_lineno', node.lineno)}\"\n",
    "                                }\n",
    "                            )\n",
    "                            all_chunks.append(doc_chunk)\n",
    "                            ast_chunks.append(doc_chunk)\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return all_chunks, ast_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710fd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "def summarise_ast_chunks_with_cache(ast_chunks, cache_path=\"summary_cache.json\"):\n",
    "    # Load cache\n",
    "    cache_file = Path(cache_path)\n",
    "    if cache_file.exists():\n",
    "        with open(cache_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            summary_cache = json.load(f)\n",
    "    else:\n",
    "        summary_cache = {}\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\" You are an expert technical writer. Summarise the following code or docstring for technical documentation:\n",
    "- Describe its purpose and functionality\n",
    "- Mention any inputs/outputs\n",
    "- Be precise and concise\n",
    "\n",
    "Code:\n",
    "```python\n",
    "{code}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb46981",
   "metadata": {},
   "outputs": [],
   "source": [
    "summariser = LLMChain(llm=llm, prompt=prompt)\n",
    "summarised_docs = []\n",
    "\n",
    "for doc in ast_chunks:\n",
    "    summary = summariser.run(code=doc.page_content)\n",
    "    summarised_docs.append(Document(\n",
    "        page_content=summary.strip(),\n",
    "        metadata=doc.metadata\n",
    "    ))\n",
    "\n",
    "return summarised_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"/path/to/your/repo\"\n",
    "\n",
    "# Step 1: Extract all + AST chunks\n",
    "all_chunks, ast_chunks = extract_chunks(repo_path)\n",
    "\n",
    "# Step 2: Summarise AST chunks\n",
    "summarised_ast_chunks = summarise_ast_chunks(ast_chunks)\n",
    "\n",
    "# Step 3: Save summarised AST content to FAISS\n",
    "vectordb = save_summaries_to_faiss(summarised_ast_chunks, index_dir=\"summarised_ast_index\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_doc_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
